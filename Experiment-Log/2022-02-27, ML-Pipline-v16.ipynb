{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e5d2c5c-0d38-4e02-bf3c-14e676c7bca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-27 10:54:37.480031: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/conda/lib/python3.8/site-packages/cv2/../../lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2022-02-27 10:54:37.480068: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.models as models\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import gc\n",
    "import argparse\n",
    "import random\n",
    "from box import Box\n",
    "import cv2\n",
    "import cvlib as cv\n",
    "import albumentations\n",
    "import timm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3011f4f1-90cb-47fc-a042-5b4f73054027",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed 고정\n",
    "def seed_everything(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # if use multi-GPU\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a396c963-2529-4d80-89f0-c245b5aa3dc9",
   "metadata": {},
   "source": [
    "# 데이터 전처리 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0add8f5-dd45-4cf1-9b94-3536fd5d3261",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ages 생성\n",
    "def get_ages(x):\n",
    "    if x < 30: return 0\n",
    "    elif x < 60: return 1\n",
    "    else: return 2\n",
    "\n",
    "# genders 생성\n",
    "def get_genders(x):\n",
    "    if x == 'male': return 0\n",
    "    else: return 1\n",
    "\n",
    "# masks 생성\n",
    "def get_masks(x):\n",
    "    if x == 'normal': return 2\n",
    "    elif x == 'incorrect_mask': return 1\n",
    "    else: return 0\n",
    "\n",
    "# # age_cats 생성\n",
    "# def get_age_cats(x):\n",
    "#     if x < 20: return 0\n",
    "#     elif x < 30: return 1\n",
    "#     elif x < 40: return 2\n",
    "#     elif x < 50: return 3\n",
    "#     elif x < 60: return 4\n",
    "#     else: return 5\n",
    "\n",
    "def get_age_cats(x):\n",
    "    if x < 25: return 0\n",
    "    elif x < 30: return 1\n",
    "    elif x < 45: return 2\n",
    "    elif x < 52: return 3\n",
    "    elif x < 57: return 4\n",
    "    elif x < 60: return 5\n",
    "    else: return 6\n",
    "\n",
    "# labels 생성\n",
    "def get_labels(masks, genders, ages):\n",
    "    return masks * 6 + genders * 3 + ages\n",
    "\n",
    "# label_cats 생성\n",
    "def get_label_cats(masks, genders, ages):\n",
    "    return masks * 12 + genders * 6 + ages\n",
    "\n",
    "# 마스크 이상치 변경\n",
    "def swap_mask(swap_li : list, df : pd.DataFrame) -> pd.DataFrame:\n",
    "    swap_df = df.copy()\n",
    "    for swap_id in swap_li:\n",
    "        _swap_df = swap_df[swap_df['id'] == swap_id]\n",
    "        \n",
    "        normal_swap_df = _swap_df[_swap_df['mask'] == 'normal']\n",
    "        incorrect_mask_swap_df = _swap_df[_swap_df['mask'] == 'incorrect_mask']\n",
    "        \n",
    "        normal_path = normal_swap_df['path'].values[0]\n",
    "        incorrect_mask_path = incorrect_mask_swap_df['path'].values[0]\n",
    "        \n",
    "        swap_df.loc[normal_swap_df.index, 'path'] = incorrect_mask_path\n",
    "        swap_df.loc[incorrect_mask_swap_df.index, 'path'] = normal_path\n",
    "    \n",
    "    return swap_df\n",
    "\n",
    "# train_df + mask 결측치 처리\n",
    "def make_train_df(df : pd.DataFrame, swap_mask_li : list, cfg) -> pd.DataFrame:\n",
    "    train_df = []\n",
    "    \n",
    "    for line in df.iloc:\n",
    "        for file in list(os.listdir(os.path.join(cfg.train_image_dir, line['path']))):\n",
    "            if file[0] == '.':\n",
    "                continue\n",
    "            \n",
    "            mask = file.split('.')[0]\n",
    "            gender = line['gender']\n",
    "            age = line['age']\n",
    "            \n",
    "            masks = get_masks(mask)\n",
    "            genders = get_genders(gender)\n",
    "            ages = get_ages(age)\n",
    "            age_cats = get_age_cats(age)\n",
    "            \n",
    "            data = {\n",
    "                'id' : line['id'],\n",
    "                'mask' : mask,\n",
    "                'gender' : gender,\n",
    "                'age' : age,\n",
    "                'masks' : masks,\n",
    "                'genders' : genders,\n",
    "                'ages' : ages,\n",
    "                'age_cats' : age_cats,\n",
    "                'labels': get_labels(masks = masks, genders = genders, ages = ages),\n",
    "                'label_cats': get_label_cats(masks = masks, genders = genders, ages = age_cats),\n",
    "                'path': os.path.join(cfg.train_image_dir, line['path'], file),\n",
    "            }\n",
    "            \n",
    "            train_df.append(data)\n",
    "            \n",
    "    train_df = pd.DataFrame(train_df)\n",
    "    \n",
    "    train_df['idx'] = train_df.index\n",
    "    \n",
    "    train_df = swap_mask(swap_li = swap_mask_li, df = train_df)\n",
    "    \n",
    "    return train_df\n",
    "\n",
    "# 성별 이상치 처리\n",
    "def swap_gender(swap_li : list, df : pd.DataFrame) -> pd.DataFrame:\n",
    "    swap_df = df.copy()\n",
    "    for swap in swap_li:\n",
    "        swap_id, swap_gender = swap\n",
    "        swap_df.loc[swap_df[swap_df['id'] == swap_id].index, 'gender'] = swap_gender\n",
    "    return swap_df\n",
    "\n",
    "# 사람 나누기 데이터 + 성별 결측치 처리\n",
    "def preprocessing_df(df : pd.DataFrame, swap_gender_li : list) -> pd.DataFrame:\n",
    "    \n",
    "    preprocessing_df = df.copy()\n",
    "    preprocessing_df = swap_gender(swap_li = swap_gender_li, df = preprocessing_df)\n",
    "    \n",
    "    preprocessing_df['ages'] = preprocessing_df['age'].apply(lambda x : get_ages(x))\n",
    "    preprocessing_df['genders'] = preprocessing_df['gender'].apply(lambda x : get_genders(x))\n",
    "    \n",
    "    preprocessing_df['cv_taget_col'] = 'ages' + '_' + preprocessing_df['ages'].astype(str) + '_' + 'genders' + '_' + preprocessing_df['genders'].astype(str)\n",
    "    \n",
    "    return preprocessing_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6466c6-37e1-4449-9a6d-bfef756b66d9",
   "metadata": {},
   "source": [
    "# 이상치 시각화 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8603a8a-baef-40cc-b809-57d25f065959",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이상치 이미지 시각화\n",
    "def show_img(img_id_li, df, cfg):\n",
    "    for img_id in img_id_li:\n",
    "        get_df = df[df['id'] == img_id]\n",
    "        \n",
    "        img_age = get_df['age'].tolist()[0]\n",
    "        img_gender = get_df['gender'].tolist()[0]\n",
    "        \n",
    "        img_path = get_df['path'].tolist()[0]\n",
    "        img_path = os.path.join(cfg.train_image_dir, img_path)\n",
    "        img_name_li = sorted(list(os.listdir(img_path)))\n",
    "        \n",
    "        fig, ax = plt.subplots(1, 7, figsize = (30, 15))\n",
    "        ax = ax.flatten()\n",
    "        \n",
    "        idx = 0\n",
    "        for _img_name in img_name_li:\n",
    "            if _img_name[0] == '.': continue\n",
    "            \n",
    "            if _img_name.split('.')[0] == 'normal': imag_name = 'normal'\n",
    "            elif _img_name.split('.')[0] == 'incorrect_mask': imag_name = 'incorrect_mask'\n",
    "            else: imag_name = 'mask'\n",
    "            \n",
    "            get_img_path = os.path.join(img_path, _img_name)\n",
    "            \n",
    "            img = Image.open(get_img_path)\n",
    "            img = np.array(img)\n",
    "            ax[idx].imshow(img)\n",
    "            ax[idx].set_title(f'{img_id} / {img_age} / {img_gender} / {imag_name}')\n",
    "            ax[idx].set_xticks([])\n",
    "            ax[idx].set_yticks([])\n",
    "            idx += 1\n",
    "            \n",
    "        plt.show()\n",
    "\n",
    "# image path로 이미지 시각화\n",
    "def path_li_show_img(path_li):\n",
    "    fig, ax = plt.subplots(1, 7, figsize = (30, 15))\n",
    "    ax = ax.flatten()\n",
    "    idx = 0\n",
    "    for path in path_li:\n",
    "        image_name = path.split('/')[-1]\n",
    "        img = Image.open(path)\n",
    "        img = np.array(img)\n",
    "        ax[idx].imshow(img)\n",
    "        ax[idx].set_title(f'{image_name}')\n",
    "        ax[idx].set_xticks([])\n",
    "        ax[idx].set_yticks([])\n",
    "        idx += 1\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62553119-8862-4f1f-bdd5-5da4de1a0a45",
   "metadata": {},
   "source": [
    "# 데이터 설정 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44405254-ea08-48ba-9396-1ee689f0b786",
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_idx 생성\n",
    "def get_val_idx(df : pd.DataFrame, target_col : str):\n",
    "    skf = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 22)\n",
    "    for trn_idx, val_idx in skf.split(df, df[target_col]):\n",
    "        yield val_idx\n",
    "\n",
    "class StratifiedSampler(torch.utils.data.Sampler):\n",
    "    \"\"\"Stratified batch sampling\n",
    "    Provides equal representation of target classes in each batch\n",
    "    \"\"\"\n",
    "    def __init__(self, y, batch_size, shuffle=True):\n",
    "        if torch.is_tensor(y):\n",
    "            y = y.cpu().numpy()\n",
    "        assert len(y.shape) == 1, 'label array must be 1D'\n",
    "        n_batches = int(len(y) / batch_size)\n",
    "        self.skf = StratifiedKFold(n_splits = n_batches, shuffle = shuffle)\n",
    "        self.X = torch.randn(len(y),1).numpy()\n",
    "        self.y = y\n",
    "        self.shuffle = shuffle\n",
    "\n",
    "    def __iter__(self):\n",
    "        if self.shuffle:\n",
    "            self.skf.random_state = torch.randint(0,int(1e8),size=()).item()\n",
    "        for train_idx, test_idx in self.skf.split(self.X, self.y):\n",
    "            yield test_idx\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "931c23a0-236a-4bed-9106-6c321c86f9af",
   "metadata": {},
   "source": [
    "# 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7a50293-f658-432a-a858-5036b9593c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CreateModel(nn.Module):\n",
    "    def __init__(self, cfg , pretrained : bool = True):\n",
    "        super(CreateModel, self).__init__()\n",
    "        self.model = timm.create_model(cfg.timm_model_name, pretrained = pretrained, num_classes = cfg.num_classes)\n",
    "\n",
    "    def forward(self, img):\n",
    "        out = self.model(img)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5fc2534a-83ba-42f8-99a6-0a421bfaad7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_f1_score(y_true, y_pred):\n",
    "    return f1_score(y_true, y_pred, average='macro')\n",
    "\n",
    "def get_acc_score(y_true, y_pred):\n",
    "    return accuracy_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2159e73-219e-4a6b-ab16-5a927be48725",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_train(model, optimizer, criterion, data_loader):\n",
    "    model.train()\n",
    "    \n",
    "    train_loss = 0\n",
    "    real_pred_li = []\n",
    "    label_pred_li = []\n",
    "    \n",
    "    for images, targets in data_loader:\n",
    "        images, targets = images.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # GA 추가시 아래 부분에 추가하기\n",
    "        #############################\n",
    "        \n",
    "        benign_outputs = model(images)\n",
    "        loss = criterion(benign_outputs, targets)\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        predicted = benign_outputs.argmax(dim=-1)\n",
    "        \n",
    "        label_pred_li.extend(predicted.detach().cpu().numpy())\n",
    "        real_pred_li.extend(targets.cpu().numpy())\n",
    "        \n",
    "#     label_pred_li = [label_cats2labels[i] for i in label_pred_li]\n",
    "#     real_pred_li = [label_cats2labels[i] for i in real_pred_li]\n",
    "    \n",
    "    train_loss /= len(data_loader)\n",
    "    train_acc = get_acc_score(y_true = real_pred_li, y_pred = label_pred_li)\n",
    "    train_fi_score = get_f1_score(y_true = real_pred_li, y_pred = label_pred_li)\n",
    "\n",
    "    return train_loss, train_acc, train_fi_score\n",
    "\n",
    "def model_eval(model, criterion, data_loader):\n",
    "    model.eval()\n",
    "    \n",
    "    val_loss = 0\n",
    "    real_pred_li = []\n",
    "    label_pred_li = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, targets in data_loader:\n",
    "            images, targets = images.to(device), targets.to(device)\n",
    "\n",
    "            benign_outputs = model(images)\n",
    "            loss = criterion(benign_outputs, targets)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            predicted = benign_outputs.argmax(dim=-1)\n",
    "        \n",
    "            label_pred_li.extend(predicted.cpu().numpy())\n",
    "            real_pred_li.extend(targets.cpu().numpy())\n",
    "    \n",
    "#     label_pred_li = [label_cats2labels[i] for i in label_pred_li]\n",
    "#     real_pred_li = [label_cats2labels[i] for i in real_pred_li]\n",
    "    \n",
    "    val_loss /= len(data_loader)\n",
    "    val_acc = get_acc_score(y_true = real_pred_li, y_pred = label_pred_li)\n",
    "    val_fi_score = get_f1_score(y_true = real_pred_li, y_pred = label_pred_li)\n",
    "   \n",
    "    return val_loss, val_acc, val_fi_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57b3b262-1703-4583-a937-28c5db3bb5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd9b38e3-426b-4f06-b500-e3631320aac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_val_pred_li(model, data_loader):\n",
    "    model.eval()\n",
    "    real_pred_li = []\n",
    "    label_pred_li = []\n",
    "    ensemble_pred_li = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, targets in data_loader:\n",
    "            images = images.to(device)\n",
    "            output = model(images)\n",
    "            \n",
    "            label = output.argmax(dim=-1)\n",
    "            label_pred_li.extend(label.cpu().numpy())\n",
    "            \n",
    "            ensemble_label = output.softmax(1)\n",
    "            ensemble_pred_li.append(ensemble_label.cpu().numpy())\n",
    "            \n",
    "            real_pred_li.extend(targets.cpu().numpy())\n",
    "            \n",
    "#     label_pred_li = [label_cats2labels[i] for i in label_pred_li]\n",
    "#     real_pred_li = [label_cats2labels[i] for i in real_pred_li]\n",
    "    \n",
    "    return label_pred_li, np.concatenate(ensemble_pred_li), real_pred_li\n",
    "\n",
    "def get_submission_pred_li(model, data_loader):\n",
    "    model.eval()\n",
    "    label_pred_li = []\n",
    "    ensemble_pred_li = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images in data_loader:\n",
    "            images = images.to(device)\n",
    "            output = model(images)\n",
    "            \n",
    "            label = output.argmax(dim=-1)\n",
    "            label_pred_li.extend(label.cpu().numpy())\n",
    "            \n",
    "            ensemble_label = output.softmax(1)\n",
    "            ensemble_pred_li.append(ensemble_label.cpu().numpy())\n",
    "            \n",
    "#     label_pred_li = [label_cats2labels[i] for i in label_pred_li]\n",
    "    \n",
    "    return label_pred_li, np.concatenate(ensemble_pred_li)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aefc2e44-fedf-4a9c-8e71-ea8f077bf8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, weight=None, gamma=2., reduction='mean'):\n",
    "        nn.Module.__init__(self)\n",
    "        self.weight = weight\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, input_tensor, target_tensor):\n",
    "        log_prob = F.log_softmax(input_tensor, dim=-1)\n",
    "        prob = torch.exp(log_prob)\n",
    "        return F.nll_loss(\n",
    "            ((1 - prob) ** self.gamma) * log_prob,\n",
    "            target_tensor,\n",
    "            weight=self.weight,\n",
    "            reduction=self.reduction\n",
    "        )\n",
    "\n",
    "\n",
    "class LabelSmoothingLoss(nn.Module):\n",
    "    def __init__(self, classes=3, smoothing=0.0, dim=-1):\n",
    "        super(LabelSmoothingLoss, self).__init__()\n",
    "        self.confidence = 1.0 - smoothing\n",
    "        self.smoothing = smoothing\n",
    "        self.cls = classes\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, pred, target):\n",
    "        pred = pred.log_softmax(dim=self.dim)\n",
    "        with torch.no_grad():\n",
    "            true_dist = torch.zeros_like(pred)\n",
    "            true_dist.fill_(self.smoothing / (self.cls - 1))\n",
    "            true_dist.scatter_(1, target.data.unsqueeze(1), self.confidence)\n",
    "        return torch.mean(torch.sum(-true_dist * pred, dim=self.dim))\n",
    "\n",
    "\n",
    "# https://gist.github.com/SuperShinyEyes/dcc68a08ff8b615442e3bc6a9b55a354\n",
    "class F1Loss(nn.Module):\n",
    "    def __init__(self, classes=3, epsilon=1e-7):\n",
    "        super().__init__()\n",
    "        self.classes = classes\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "        assert y_pred.ndim == 2\n",
    "        assert y_true.ndim == 1\n",
    "        y_true = F.one_hot(y_true, self.classes).to(torch.float32)\n",
    "        y_pred = F.softmax(y_pred, dim=1)\n",
    "\n",
    "        tp = (y_true * y_pred).sum(dim=0).to(torch.float32)\n",
    "        tn = ((1 - y_true) * (1 - y_pred)).sum(dim=0).to(torch.float32)\n",
    "        fp = ((1 - y_true) * y_pred).sum(dim=0).to(torch.float32)\n",
    "        fn = (y_true * (1 - y_pred)).sum(dim=0).to(torch.float32)\n",
    "\n",
    "        precision = tp / (tp + fp + self.epsilon)\n",
    "        recall = tp / (tp + fn + self.epsilon)\n",
    "\n",
    "        f1 = 2 * (precision * recall) / (precision + recall + self.epsilon)\n",
    "        f1 = f1.clamp(min=self.epsilon, max=1 - self.epsilon)\n",
    "        return 1 - f1.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892bc074-57cc-4c87-bb82-20936b25b1cb",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 환경 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac961a79-bcba-46d4-bcc4-435ce0cf453e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이상치 list\n",
    "# swap_gender_li = ['id', '바꿀 성별']\n",
    "# swap_mask_li = ['id']\n",
    "swap_gender_li = [[\"001498-1\", \"female\"], [\"004432\", \"female\"],[\"005223\", \"female\"], \n",
    "                  ['006359', 'male'], ['006360', 'male'], ['006361', 'male'], ['006362', 'male'], ['006363', 'male'], ['006364', 'male'],]\n",
    "swap_mask_li = ['000020', '004418', '005227']\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "config = {\n",
    "    'seed' : 22,\n",
    "    \n",
    "    'image_size' : [512, 384],\n",
    "    'image_normal_mean' : [0.5, 0.5, 0.5],\n",
    "    'image_normal_std' : [0.2, 0.2, 0.2],\n",
    "    \n",
    "#     'image_size' : [380, 380],\n",
    "#     'image_normal_mean' : [0.485, 0.456, 0.406],\n",
    "#     'image_normal_std' : [0.229, 0.224, 0.225],\n",
    "    \n",
    "    'num_workers' : 3,\n",
    "    'epochs' : 20,\n",
    "    'batch_size' : 128,\n",
    "    'lr' : 0.00009,\n",
    "    'oof' : 1,\n",
    "    'num_classes' : 18,\n",
    "    \n",
    "#     cel\n",
    "#     labelsmoothing\n",
    "#     focal\n",
    "#     f1\n",
    "#     'loss' : 'cel',\n",
    "    \n",
    "#     'loss' : 'focal',\n",
    "#     'weight' : torch.tensor([0.158863, 0.139296, 1.000000, 0.494792, 0.101064, 0.494792]).to(device),\n",
    "    \n",
    "    'loss' : 'labelsmoothing',\n",
    "    'smoothing' : 0.1,\n",
    "    \n",
    "    'train_data_name' : 'train.csv',\n",
    "    'train_data_dir' : '/opt/ml/input/data/train',\n",
    "    'train_image_dir' : '/opt/ml/input/data/train/images',\n",
    "    \n",
    "    'submission_data_name' : 'info.csv',\n",
    "    'submission_data_dir' : '/opt/ml/input/data/eval',\n",
    "    'submission_image_dir' : '/opt/ml/input/data/eval/images',\n",
    "    \n",
    "    'model_dir' : '/opt/ml/model',\n",
    "    # 저장할 모델병\n",
    "    'model_name' : 'regnety_002_labels_gray_pseudo_labeling',\n",
    "    \n",
    "    # timm 에 존재하는 모델 이름\n",
    "    'timm_model_name' : 'regnety_002',\n",
    "    \n",
    "    # 학습 타겟\n",
    "    'tagets_col' : 'labels',\n",
    "    'split_col' : 'label_cats',\n",
    "    'cv_taget_col' : 'cv_taget_col',\n",
    "    \n",
    "    # 저장할 파일명\n",
    "    'file_name' : 'regnety_002_labels_gray_pseudo_labeling.csv',\n",
    "}\n",
    "\n",
    "config = Box(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cf47fce1-02a4-4a69-9611-222414bf7fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 변환할 transform\n",
    "# from albumentations import *\n",
    "# from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "# def image_face_crop(image, **kwargs):\n",
    "#     face, confidence = cv.detect_face(image)\n",
    "#     if not face : return image\n",
    "#     x, y, w, h = face[0]\n",
    "#     H, W, C = image.shape\n",
    "#     image = image[max(y - 100, 0) : min(h + 100, H), max(0 , x - 100) : min(w + 100, W)]\n",
    "#     return image\n",
    "\n",
    "# transform = {\n",
    "#         \"train\": Compose(\n",
    "#             [\n",
    "# #                 Lambda(image = image_face_crop, p = 1.0),\n",
    "#                 Resize(config.image_size[0], config.image_size[1], Image.BILINEAR, p = 1.0),\n",
    "#                 Normalize(mean=config.image_normal_mean, std=config.image_normal_std, p = 1.0),\n",
    "#                 ToGray(p = 1.0),\n",
    "#                 ToTensorV2(p = 1.0),\n",
    "#             ]\n",
    "#         ),  \n",
    "#         \"val\": Compose(\n",
    "#             [\n",
    "# #                 Lambda(image = image_face_crop, p = 1.0),\n",
    "#                 Resize(config.image_size[0], config.image_size[1], Image.BILINEAR, p = 1.0),\n",
    "#                 Normalize(mean=config.image_normal_mean, std=config.image_normal_std, p = 1.0),\n",
    "#                 ToGray(p = 1.0),\n",
    "#                 ToTensorV2(p = 1.0),\n",
    "#             ]\n",
    "#         ),\n",
    "#     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "915e4875-bfd3-476d-9906-95daf128bb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class CustomDataset(Dataset):\n",
    "#     def __init__(self, df : pd.DataFrame, cfg, transform = None, mode : bool = True):\n",
    "#         self.mode = mode\n",
    "#         self.df = df\n",
    "#         if self.mode:\n",
    "#             self.img_paths = self.df['path'].tolist()\n",
    "#             self.targets = self.df[cfg.tagets_col].tolist()\n",
    "#             self.split_targets = self.df[cfg.split_col].tolist()\n",
    "#         else:\n",
    "#             self.img_paths = [os.path.join(cfg.submission_image_dir, img_id) for img_id in self.df.ImageID]\n",
    "#         self.transform = transform\n",
    "\n",
    "#     def __getitem__(self, index):\n",
    "#         image = Image.open(self.img_paths[index])\n",
    "#         if self.transform:\n",
    "#             image = self.transform(image = np.array(image))['image']\n",
    "        \n",
    "#         # 이 부분에 해당 라벨에 따른 데이터 변환 여부 추가\n",
    "#         # val 데이터의 경우 데이터 변환이 일어나면 안되기 때문에\n",
    "#         # if self.데이터 변환해주는 transform:\n",
    "#         #     if self.targets[index].data == labels: <- 확률적으로\n",
    "#         #          image = self.데이터 변환해주는 transform(image)\n",
    "#         # 데이터 변환\n",
    "        \n",
    "#         if self.mode:\n",
    "#             targets = torch.tensor(self.targets[index])\n",
    "#             return image, targets\n",
    "        \n",
    "#         else: return image\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.img_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "94152321-165a-4a6b-8199-cf0d21875195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 변환할 transform\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import Resize, ToTensor, Normalize, Lambda, RandomHorizontalFlip, ToPILImage, CenterCrop, Grayscale\n",
    "\n",
    "def image_face_crop(image):\n",
    "    image = np.array(image)\n",
    "    face, confidence = cv.detect_face(image)\n",
    "    if not face : return image\n",
    "    x, y, w, h = face[0]\n",
    "    H, W, C = image.shape\n",
    "    image = image[max(y - 100, 0) : min(h + 100, H), max(0 , x - 100) : min(w + 100, W)]\n",
    "    return image\n",
    "\n",
    "transform = {\n",
    "        \"train\": transforms.Compose(\n",
    "            [\n",
    "#                 CenterCrop(384),\n",
    "                Resize(config.image_size, Image.BILINEAR),\n",
    "                ToTensor(),\n",
    "                Normalize(mean=config.image_normal_mean, std=config.image_normal_std),\n",
    "                Grayscale(num_output_channels = 3),\n",
    "            ]\n",
    "        ),\n",
    "        \"val\": transforms.Compose(\n",
    "            [\n",
    "#                 CenterCrop(384),\n",
    "                Resize(config.image_size, Image.BILINEAR),\n",
    "                ToTensor(),\n",
    "                Normalize(mean=config.image_normal_mean, std=config.image_normal_std),\n",
    "                Grayscale(num_output_channels = 3),\n",
    "            ]\n",
    "        ),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "652981eb-cbff-47c6-b974-b2266667af60",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, df : pd.DataFrame, cfg, transform = None, mode : bool = True):\n",
    "        self.mode = mode\n",
    "        self.df = df\n",
    "        if self.mode:\n",
    "            self.img_paths = self.df['path'].tolist()\n",
    "            self.targets = self.df[cfg.tagets_col].tolist()\n",
    "            self.split_targets = self.df[cfg.split_col].tolist()\n",
    "        else:\n",
    "            self.img_paths = [os.path.join(cfg.submission_image_dir, img_id) for img_id in self.df.ImageID]\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = Image.open(self.img_paths[index])\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        # 이 부분에 해당 라벨에 따른 데이터 변환 여부 추가\n",
    "        # val 데이터의 경우 데이터 변환이 일어나면 안되기 때문에\n",
    "        # if self.데이터 변환해주는 transform:\n",
    "        #     if self.targets[index].data == labels: <- 확률적으로\n",
    "        #          image = self.데이터 변환해주는 transform(image)\n",
    "        # 데이터 변환\n",
    "        \n",
    "        if self.mode:\n",
    "            targets = torch.tensor(self.targets[index])\n",
    "            return image, targets\n",
    "        \n",
    "        else: return image\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1966b7e-b676-41fe-a0aa-bf6d233824c6",
   "metadata": {},
   "source": [
    "# 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6c9bfae8-4bda-4749-949b-e3389a6fed43",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(config.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "01270fba-3558-42dc-81e9-e5574e6c963a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(config.train_data_dir, config.train_data_name))\n",
    "submission = pd.read_csv(os.path.join(config.submission_data_dir, config.submission_data_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52932149-7935-4bd5-92bf-1f706d951914",
   "metadata": {},
   "source": [
    "# 이상치 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13d2daf-b3a7-442e-9d94-16c8d6b96321",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_img(img_id_li =[\n",
    "    # Mask 오류\n",
    "    '000020', '004418', '005227',\n",
    "    # Gender 오류\n",
    "    \"004432\", \"005223\", \"006359\", \"006360\",\"006361\", \"006362\", \"006363\", \"006364\", \"006424\",], df = df, cfg = config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c589239-662f-4af2-add9-7648b8c77a68",
   "metadata": {},
   "source": [
    "# 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e1e94a30-cb52-4dd5-87c6-68ca231afad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pseudo_dataset(trn_df, val_df, submission_df, val_label_pred_li, submission_label_pred_li, cfg):\n",
    "    pseudo_trn_df = trn_df.copy()\n",
    "    pseudo_val_df = val_df.copy()\n",
    "    pseudo_submission_df = pd.DataFrame(columns = trn_df.columns)\n",
    "\n",
    "    pseudo_val_df[cfg.tagets_col] = val_label_pred_li\n",
    "\n",
    "    pseudo_submission_df['path'] = [os.path.join(cfg.submission_image_dir, img_id) for img_id in submission_df.ImageID]\n",
    "    pseudo_submission_df[cfg.tagets_col] = submission_label_pred_li\n",
    "\n",
    "    pseudo_df = pd.concat([pseudo_trn_df, pseudo_val_df, pseudo_submission_df]).reset_index(drop = True)\n",
    "\n",
    "    return pseudo_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45fb0b8e-eff7-4ace-abce-7e882e9d84d0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1fold, epoch: 1, lr: 9e-05, train_loss: 1.8183, train_acc: 0.5527, train_f1: 0.2430, val_loss: 1.2660, val_acc: 0.7750, val_fi: 0.4345, 학습시간: 66.10061168670654 \n",
      "\n",
      "0.4345148319303232 모델 저장\n",
      "1fold, epoch: 2, lr: 9e-05, train_loss: 1.0025, train_acc: 0.8626, train_f1: 0.5635, val_loss: 0.9468, val_acc: 0.8809, val_fi: 0.6338, 학습시간: 66.27475070953369 \n",
      "\n",
      "0.6337837355506032 모델 저장\n",
      "1fold, epoch: 3, lr: 9e-05, train_loss: 0.7889, train_acc: 0.9383, train_f1: 0.7071, val_loss: 0.9082, val_acc: 0.8820, val_fi: 0.6726, 학습시간: 66.76957726478577 \n",
      "\n",
      "0.6725612328956447 모델 저장\n",
      "1fold, epoch: 4, lr: 9e-05, train_loss: 0.7076, train_acc: 0.9676, train_f1: 0.8264, val_loss: 0.9028, val_acc: 0.8843, val_fi: 0.7366, 학습시간: 67.50463390350342 \n",
      "\n",
      "0.7366296884230398 모델 저장\n",
      "1fold, epoch: 5, lr: 9e-05, train_loss: 0.6629, train_acc: 0.9862, train_f1: 0.9383, val_loss: 0.8988, val_acc: 0.8878, val_fi: 0.7904, 학습시간: 68.16871428489685 \n",
      "\n",
      "0.7904252457397992 모델 저장\n",
      "1fold, epoch: 6, lr: 9e-05, train_loss: 0.6410, train_acc: 0.9936, train_f1: 0.9759, val_loss: 0.9042, val_acc: 0.8941, val_fi: 0.7786, 학습시간: 69.14929103851318 \n",
      "\n",
      "1fold, epoch: 7, lr: 9e-05, train_loss: 0.6301, train_acc: 0.9966, train_f1: 0.9903, val_loss: 0.9126, val_acc: 0.8981, val_fi: 0.8030, 학습시간: 67.86802887916565 \n",
      "\n",
      "0.8030499522358987 모델 저장\n",
      "1fold, epoch: 8, lr: 9e-05, train_loss: 0.6229, train_acc: 0.9983, train_f1: 0.9941, val_loss: 0.9384, val_acc: 0.8899, val_fi: 0.7943, 학습시간: 68.20291757583618 \n",
      "\n",
      "1fold, epoch: 9, lr: 9e-05, train_loss: 0.6232, train_acc: 0.9976, train_f1: 0.9979, val_loss: 0.9294, val_acc: 0.8949, val_fi: 0.7827, 학습시간: 66.1712167263031 \n",
      "\n",
      "1fold, epoch: 10, lr: 9e-05, train_loss: 0.6266, train_acc: 0.9971, train_f1: 0.9924, val_loss: 0.9405, val_acc: 0.8909, val_fi: 0.7608, 학습시간: 66.32198405265808 \n",
      "\n",
      "1fold, epoch: 11, lr: 9e-05, train_loss: 0.6208, train_acc: 0.9977, train_f1: 0.9959, val_loss: 0.9281, val_acc: 0.8928, val_fi: 0.7970, 학습시간: 67.10695457458496 \n",
      "\n",
      "1fold, epoch: 12, lr: 9e-06, train_loss: 0.6156, train_acc: 0.9997, train_f1: 0.9998, val_loss: 0.9282, val_acc: 0.8946, val_fi: 0.8032, 학습시간: 68.24665307998657 \n",
      "\n",
      "0.8031891601355379 모델 저장\n",
      "1fold, epoch: 13, lr: 9e-06, train_loss: 0.6151, train_acc: 0.9997, train_f1: 0.9998, val_loss: 0.9281, val_acc: 0.8957, val_fi: 0.7960, 학습시간: 68.14250349998474 \n",
      "\n",
      "1fold, epoch: 14, lr: 9e-06, train_loss: 0.6141, train_acc: 0.9998, train_f1: 0.9998, val_loss: 0.9264, val_acc: 0.8944, val_fi: 0.7929, 학습시간: 67.0706672668457 \n",
      "\n",
      "1fold, epoch: 15, lr: 9e-06, train_loss: 0.6138, train_acc: 0.9999, train_f1: 0.9998, val_loss: 0.9251, val_acc: 0.8954, val_fi: 0.7983, 학습시간: 68.91574335098267 \n",
      "\n",
      "1fold, epoch: 16, lr: 9e-06, train_loss: 0.6136, train_acc: 0.9998, train_f1: 0.9997, val_loss: 0.9223, val_acc: 0.8960, val_fi: 0.8008, 학습시간: 67.73567509651184 \n",
      "\n",
      "1fold, epoch: 17, lr: 9e-06, train_loss: 0.6146, train_acc: 0.9998, train_f1: 0.9991, val_loss: 0.9247, val_acc: 0.8933, val_fi: 0.7878, 학습시간: 67.29669213294983 \n",
      "\n",
      "1fold, epoch: 18, lr: 9.000000000000001e-07, train_loss: 0.6138, train_acc: 0.9997, train_f1: 0.9997, val_loss: 0.9250, val_acc: 0.8941, val_fi: 0.7862, 학습시간: 67.299245595932 \n",
      "\n",
      "1fold, epoch: 19, lr: 9.000000000000001e-07, train_loss: 0.6137, train_acc: 0.9997, train_f1: 0.9997, val_loss: 0.9230, val_acc: 0.8938, val_fi: 0.7947, 학습시간: 66.78001666069031 \n",
      "\n",
      "1fold, epoch: 20, lr: 9.000000000000001e-07, train_loss: 0.6134, train_acc: 0.9998, train_f1: 0.9998, val_loss: 0.9290, val_acc: 0.8928, val_fi: 0.7973, 학습시간: 66.47870755195618 \n",
      "\n",
      "pseudo_1fold, epoch: 1, lr: 9e-05, train_loss: 1.4064, train_acc: 0.7205, train_f1: 0.4829, val_loss: 0.9171, val_acc: 0.8825, val_fi: 0.6522, 학습시간: 126.24856066703796 \n",
      "\n",
      "0.6521680880838612 모델 저장\n",
      "pseudo_1fold, epoch: 2, lr: 9e-05, train_loss: 0.8164, train_acc: 0.9181, train_f1: 0.7848, val_loss: 0.8946, val_acc: 0.8957, val_fi: 0.7802, 학습시간: 123.1933605670929 \n",
      "\n",
      "0.7801779756792951 모델 저장\n",
      "pseudo_1fold, epoch: 3, lr: 9e-05, train_loss: 0.7325, train_acc: 0.9520, train_f1: 0.8958, val_loss: 0.9241, val_acc: 0.8973, val_fi: 0.7965, 학습시간: 125.8053822517395 \n",
      "\n",
      "0.7964761333185106 모델 저장\n",
      "pseudo_1fold, epoch: 4, lr: 9e-05, train_loss: 0.6869, train_acc: 0.9709, train_f1: 0.9365, val_loss: 0.9526, val_acc: 0.8938, val_fi: 0.7957, 학습시간: 122.64643454551697 \n",
      "\n",
      "pseudo_1fold, epoch: 5, lr: 9e-05, train_loss: 0.6600, train_acc: 0.9828, train_f1: 0.9622, val_loss: 0.9843, val_acc: 0.8933, val_fi: 0.8009, 학습시간: 122.20366477966309 \n",
      "\n",
      "0.8008995337787044 모델 저장\n",
      "pseudo_1fold, epoch: 6, lr: 9e-05, train_loss: 0.6455, train_acc: 0.9877, train_f1: 0.9747, val_loss: 1.0142, val_acc: 0.8946, val_fi: 0.8036, 학습시간: 126.12206292152405 \n",
      "\n",
      "0.8035663222917575 모델 저장\n",
      "pseudo_1fold, epoch: 7, lr: 9e-05, train_loss: 0.6339, train_acc: 0.9927, train_f1: 0.9837, val_loss: 1.0192, val_acc: 0.8944, val_fi: 0.7978, 학습시간: 124.90409684181213 \n",
      "\n",
      "pseudo_1fold, epoch: 8, lr: 9e-05, train_loss: 0.6258, train_acc: 0.9959, train_f1: 0.9930, val_loss: 1.0190, val_acc: 0.8933, val_fi: 0.7999, 학습시간: 126.71131324768066 \n",
      "\n",
      "pseudo_1fold, epoch: 9, lr: 9e-06, train_loss: 0.6208, train_acc: 0.9977, train_f1: 0.9965, val_loss: 1.0448, val_acc: 0.8946, val_fi: 0.8033, 학습시간: 126.35409307479858 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "submission_dataset = CustomDataset(df = submission, \n",
    "                                   cfg = config,\n",
    "                                   transform = transform['val'],\n",
    "                                   mode = False,\n",
    "                                  )\n",
    "\n",
    "submission_loder = DataLoader(submission_dataset,\n",
    "                                batch_size = config.batch_size,\n",
    "                                num_workers = config.num_workers,\n",
    "                                shuffle = False,\n",
    "                             )\n",
    "\n",
    "\n",
    "pre_df = preprocessing_df(df = df, swap_gender_li = swap_gender_li)\n",
    "train_df = make_train_df(df = pre_df, swap_mask_li = swap_mask_li, cfg = config)\n",
    "\n",
    "all_idx_li = pre_df.index.tolist()\n",
    "val_idx_li = get_val_idx(df = pre_df, target_col = config.cv_taget_col)\n",
    "\n",
    "total_start_time = time.time()\n",
    "\n",
    "for fold_num in range(1, config.oof + 1):\n",
    "    fold_start_time = time.time()\n",
    "    \n",
    "    # trn, val 데이터 셋\n",
    "    val_idx = next(val_idx_li)\n",
    "    trn_idx = list(set(all_idx_li) - set(val_idx.tolist()))\n",
    "    \n",
    "    val_id_df = pre_df.iloc[val_idx, :]\n",
    "    trn_id_df = pre_df.iloc[trn_idx, :]\n",
    "    \n",
    "    val_df = train_df.set_index('id').loc[val_id_df['id'].tolist(), :].reset_index()\n",
    "    trn_df = train_df.set_index('id').loc[trn_id_df['id'].tolist(), :].reset_index()\n",
    "    \n",
    "    # 이 부분에 클래스가 적은 데이터 증강 함수 추가\n",
    "    ########################################3\n",
    "    \n",
    "    # 배치 단위 데이터 생성 부분\n",
    "    #########################\n",
    "    \n",
    "    \n",
    "    # dataset 구축\n",
    "    trn_dataset = CustomDataset(df = trn_df,\n",
    "                                cfg = config,\n",
    "                                transform = transform['train'],\n",
    "                                mode = True,\n",
    "                               )\n",
    "    \n",
    "    train_loder = DataLoader(trn_dataset,\n",
    "                           batch_size = config.batch_size,\n",
    "                           num_workers = config.num_workers,\n",
    "                           shuffle = True,\n",
    "                            )\n",
    "    \n",
    "    \n",
    "#     sampler = StratifiedSampler(y = np.array(trn_dataset.split_targets), \n",
    "#                                 batch_size = config.batch_size, \n",
    "#                                 shuffle = True)\n",
    "    \n",
    "#     train_loder = DataLoader(trn_dataset,\n",
    "#                              num_workers = config.num_workers,\n",
    "#                              batch_sampler = sampler)\n",
    "    \n",
    "    \n",
    "    val_dataset = CustomDataset(df = val_df,\n",
    "                                cfg = config,\n",
    "                                transform = transform['val'],\n",
    "                                mode = True,)\n",
    "    \n",
    "    val_loder = DataLoader(val_dataset,\n",
    "                           batch_size = config.batch_size,\n",
    "                           num_workers = config.num_workers,\n",
    "                           shuffle = False,)\n",
    "    \n",
    "    # 모델 정의\n",
    "    model = CreateModel(cfg = config, pretrained = True).to(device)\n",
    "\n",
    "    # loss 설정\n",
    "    if config.loss == 'cel':\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "    elif config.loss == 'labelsmoothing':\n",
    "        criterion = LabelSmoothingLoss(classes=config.num_classes, smoothing = config.smoothing, dim=-1)\n",
    "    elif config.loss == 'focal':\n",
    "        criterion = FocalLoss(weight = config.weight, gamma=2.0, reduction='mean')\n",
    "    elif config.loss == 'f1':\n",
    "        criterion = F1Loss(classes=config.num_classes, epsilon=1e-7)\n",
    "    else:\n",
    "        print('not loss')\n",
    "    \n",
    "    # optimizer 설정\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=config.lr)\n",
    "    \n",
    "    # scheduler 설정\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor = 0.1, eps = 1e-09, patience = 5)\n",
    "   \n",
    "    # besf_metric 설정\n",
    "    besf_fi = 0\n",
    "    \n",
    "    for epoch in range(1, config.epochs + 1):\n",
    "        epoch_start_time = time.time()\n",
    "        \n",
    "        train_loss, train_acc, train_fi_score = model_train(model = model, \n",
    "                                                            optimizer = optimizer, \n",
    "                                                            criterion = criterion, \n",
    "                                                            data_loader = train_loder)\n",
    "        \n",
    "        val_loss, val_acc, val_fi_score, = model_eval(model = model,\n",
    "                                                      criterion = criterion,\n",
    "                                                      data_loader = val_loder)\n",
    "        \n",
    "        # 학습률\n",
    "        now_lr = get_lr(optimizer = optimizer)\n",
    "        \n",
    "        epoch_end_time = time.time()\n",
    "        \n",
    "        print(f'''{fold_num}fold, epoch: {epoch}, lr: {now_lr}, train_loss: {train_loss:.4f}, train_acc: {train_acc:.4f}, train_f1: {train_fi_score:.4f}, val_loss: {val_loss:.4f}, val_acc: {val_acc:.4f}, val_fi: {val_fi_score:.4f}, 학습시간: {epoch_end_time - epoch_start_time} \\n''')\n",
    "\n",
    "        # 스케줄러\n",
    "        scheduler.step(val_loss)\n",
    "        \n",
    "        # 모델 저장\n",
    "        if besf_fi < val_fi_score:\n",
    "            besf_fi = val_fi_score\n",
    "            torch.save(model.state_dict(), os.path.join(config.model_dir, f'{fold_num}fold_befor_pseudo_model.pt'))\n",
    "            print(besf_fi, '모델 저장')\n",
    "    \n",
    "    # pseudo 데이터셋 생성\n",
    "    model = CreateModel(cfg = config, pretrained = False).to(device)\n",
    "    model.load_state_dict(torch.load(os.path.join(config.model_dir, f'{fold_num}fold_befor_pseudo_model.pt')))\n",
    "    \n",
    "    val_label_pred_li, val_ensemble_pred_li, real_pred_li = get_val_pred_li(model = model, data_loader = val_loder)\n",
    "    submission_label_pred_li, submission_ensemble_pred_li = get_submission_pred_li(model = model, data_loader = submission_loder)\n",
    "    \n",
    "    pseudo_trn_df = get_pseudo_dataset(trn_df = trn_df, val_df = val_df, submission_df = submission, val_label_pred_li = val_label_pred_li, submission_label_pred_li = submission_label_pred_li, cfg = config)\n",
    "    \n",
    "    # dataset 구축\n",
    "    trn_dataset = CustomDataset(df = pseudo_trn_df,\n",
    "                                cfg = config,\n",
    "                                transform = transform['train'],\n",
    "                                mode = True,\n",
    "                               )\n",
    "    \n",
    "    train_loder = DataLoader(trn_dataset,\n",
    "                           batch_size = config.batch_size,\n",
    "                           num_workers = config.num_workers,\n",
    "                           shuffle = True,\n",
    "                            )\n",
    "    \n",
    "    # pseudo Model 학습\n",
    "    \n",
    "    # 모델 정의\n",
    "    model = CreateModel(cfg = config, pretrained = True).to(device)\n",
    "\n",
    "    # loss 설정\n",
    "    if config.loss == 'cel':\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "    elif config.loss == 'labelsmoothing':\n",
    "        criterion = LabelSmoothingLoss(classes=config.num_classes, smoothing = config.smoothing, dim=-1)\n",
    "    elif config.loss == 'focal':\n",
    "        criterion = FocalLoss(weight = config.weight, gamma=2.0, reduction='mean')\n",
    "    elif config.loss == 'f1':\n",
    "        criterion = F1Loss(classes=config.num_classes, epsilon=1e-7)\n",
    "    else:\n",
    "        print('not loss')\n",
    "    \n",
    "    # optimizer 설정\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=config.lr)\n",
    "    \n",
    "    # scheduler 설정\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor = 0.1, eps = 1e-09, patience = 5)\n",
    "   \n",
    "    # besf_metric 설정\n",
    "    besf_fi = 0\n",
    "    \n",
    "    for epoch in range(1, config.epochs + 1):\n",
    "        epoch_start_time = time.time()\n",
    "        \n",
    "        train_loss, train_acc, train_fi_score = model_train(model = model, \n",
    "                                                            optimizer = optimizer, \n",
    "                                                            criterion = criterion, \n",
    "                                                            data_loader = train_loder)\n",
    "        \n",
    "        val_loss, val_acc, val_fi_score, = model_eval(model = model,\n",
    "                                                      criterion = criterion,\n",
    "                                                      data_loader = val_loder)\n",
    "        \n",
    "        # 학습률\n",
    "        now_lr = get_lr(optimizer = optimizer)\n",
    "        \n",
    "        epoch_end_time = time.time()\n",
    "        \n",
    "        print(f'''pseudo_{fold_num}fold, epoch: {epoch}, lr: {now_lr}, train_loss: {train_loss:.4f}, train_acc: {train_acc:.4f}, train_f1: {train_fi_score:.4f}, val_loss: {val_loss:.4f}, val_acc: {val_acc:.4f}, val_fi: {val_fi_score:.4f}, 학습시간: {epoch_end_time - epoch_start_time} \\n''')\n",
    "\n",
    "        # 스케줄러\n",
    "        scheduler.step(val_loss)\n",
    "        \n",
    "        # 모델 저장\n",
    "        if besf_fi < val_fi_score:\n",
    "            besf_fi = val_fi_score\n",
    "            torch.save(model.state_dict(), os.path.join(config.model_dir, f'{fold_num}fold_{config.model_name}.pt'))\n",
    "            print(besf_fi, '모델 저장')\n",
    "    \n",
    "    \n",
    "    fold_end_time = time.time()\n",
    "    \n",
    "    print(f'{fold_num}fold 훈련 시간: {fold_end_time - fold_start_time} \\n')\n",
    "    \n",
    "    # 메모리 정리\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "total_end_time = time.time()\n",
    "print(f'총 훈련 시간: {total_end_time - total_start_time}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aee6d31-3204-4d9c-b096-dd3973f04ca7",
   "metadata": {},
   "source": [
    "# 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631ce276-82eb-4b71-b87e-d78e7ff584be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# submission 데이터 정의\n",
    "submission_dataset = CustomDataset(df = submission, \n",
    "                                   cfg = config,\n",
    "                                   transform = transform['val'],\n",
    "                                   mode = False,\n",
    "                                  )\n",
    "\n",
    "submission_loder = DataLoader(submission_dataset,\n",
    "                                batch_size = config.batch_size,\n",
    "                                num_workers = config.num_workers,\n",
    "                                shuffle = False,\n",
    "                             )\n",
    "\n",
    "submission_label_oof = np.zeros((submission.shape[0], config.num_classes))\n",
    "\n",
    "pre_df = preprocessing_df(df = df, swap_gender_li = swap_gender_li)\n",
    "train_df = make_train_df(df = pre_df, swap_mask_li = swap_mask_li, cfg = config)\n",
    "\n",
    "all_idx_li = pre_df.index.tolist()\n",
    "val_idx_li = get_val_idx(df = pre_df, target_col = config.cv_taget_col)\n",
    "\n",
    "real_labels = []\n",
    "pred_labels = []\n",
    "idx_li = []\n",
    "\n",
    "for fold_num in range(1, config.oof + 1):\n",
    "    fold_start_time = time.time()\n",
    "    \n",
    "    # val\n",
    "    val_idx = next(val_idx_li)\n",
    "    trn_idx = list(set(all_idx_li) - set(val_idx.tolist()))\n",
    "    \n",
    "    val_id_df = pre_df.iloc[val_idx, :]\n",
    "    trn_id_df = pre_df.iloc[trn_idx, :]\n",
    "    \n",
    "    val_df = train_df.set_index('id').loc[val_id_df['id'].tolist(), :].reset_index()\n",
    "    trn_df = train_df.set_index('id').loc[trn_id_df['id'].tolist(), :].reset_index()\n",
    "    \n",
    "    val_dataset = CustomDataset(df = val_df, \n",
    "                                cfg = config,\n",
    "                                transform = transform['val'],\n",
    "                                mode = True,\n",
    "                               )\n",
    "    \n",
    "    val_loder = DataLoader(val_dataset,\n",
    "                            batch_size = config.batch_size,\n",
    "                           num_workers = config.num_workers,\n",
    "                            shuffle = False,)\n",
    "    \n",
    "    # 모델 로드\n",
    "    model = CreateModel(cfg = config, pretrained = False).to(device)\n",
    "    model.load_state_dict(torch.load(os.path.join(config.model_dir, f'{fold_num}fold_{config.model_name}.pt')))\n",
    "    \n",
    "    # val 평가\n",
    "    val_label_pred_li, val_ensemble_pred_li, real_pred_li = get_val_pred_li(model = model, data_loader = val_loder)\n",
    "    \n",
    "    real_labels += real_pred_li\n",
    "    pred_labels += val_label_pred_li\n",
    "    idx_li += val_df['idx'].tolist()\n",
    "    \n",
    "    # submission 평가\n",
    "    submission_label_pred_li, submission_ensemble_pred_li = get_submission_pred_li(model = model, data_loader = submission_loder)\n",
    "    submission_label_oof += submission_ensemble_pred_li / config.oof\n",
    "    \n",
    "    fold_end_time = time.time()\n",
    "\n",
    "    _acc = get_acc_score(y_true = real_pred_li, y_pred = val_label_pred_li)\n",
    "    _f1_score = get_f1_score(y_true = real_pred_li, y_pred = val_label_pred_li)\n",
    "\n",
    "    print(f'{fold_num}fold 훈련 시간: {fold_end_time - fold_start_time}, acc: {_acc}, f1_score: {_f1_score} \\n')\n",
    "\n",
    "# pred_li = submission_label_oof.argmax(1).tolist()\n",
    "# pred_li = [label_cats2labels[i] for i in pred_li]\n",
    "# submission['ans'] = pred_li\n",
    "\n",
    "submission['ans'] = submission_label_oof.argmax(1).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30dc6c8c-71cf-4efc-9ddb-be399c73b230",
   "metadata": {},
   "source": [
    "# 결과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc9113e-f0e7-44f1-b090-fd1bce9c8b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_f1 = get_f1_score(y_true = real_labels, y_pred = pred_labels)\n",
    "train_acc = get_acc_score(y_true = real_labels, y_pred = pred_labels)\n",
    "train_confusion_matrix = pd.DataFrame((confusion_matrix(y_true = real_labels, y_pred = pred_labels)))\n",
    "print(f'train confusion_matrix')\n",
    "display(train_confusion_matrix.style.background_gradient(cmap='YlOrRd', axis = 1))\n",
    "print(f'train fi : {train_f1:.4f}, train acc: {train_acc:.4f} \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dbd9608-13c6-4866-bce9-309ce4387da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels 로 masks, genders, ages 역추적\n",
    "labels2masks_genders_ages = {}\n",
    "for line in train_df[~(train_df.duplicated(subset=[config.tagets_col]))].iloc:\n",
    "    labels2masks_genders_ages[line[config.tagets_col]] = str(line['masks']) + '-' + str(line['genders']) + '-' + str(line['ages'])\n",
    "\n",
    "# 틀린 이미지 시각화\n",
    "image_show_df = train_df.iloc[idx_li, :].reset_index(drop =True)\n",
    "image_show_df['pred_labels'] = pred_labels\n",
    "false_image_show_df = image_show_df[image_show_df[config.tagets_col] != image_show_df['pred_labels']]\n",
    "labels_li = [i for i in range(config.num_classes)]\n",
    "for labels in labels_li:\n",
    "    _false_image_show_df = false_image_show_df[false_image_show_df[config.tagets_col] == labels]\n",
    "    path_labels_pred_labels_li = _false_image_show_df[['path', config.tagets_col, 'pred_labels']].values[:7]\n",
    "    \n",
    "    idx = 0\n",
    "    fig, ax = plt.subplots(1, 7, figsize = (30, 15))\n",
    "    ax = ax.flatten()\n",
    "    for path_labels_pred_labels in path_labels_pred_labels_li:\n",
    "        img = Image.open(path_labels_pred_labels[0])\n",
    "        img = np.array(img)\n",
    "        ax[idx].imshow(img)\n",
    "        ax[idx].set_title(f'true {path_labels_pred_labels[1]} - {labels2masks_genders_ages[path_labels_pred_labels[1]]} / pred {path_labels_pred_labels[2]} - {labels2masks_genders_ages[path_labels_pred_labels[2]]} ')\n",
    "        ax[idx].set_xticks([])\n",
    "        ax[idx].set_yticks([])\n",
    "        idx += 1\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a4b84b-969f-4c34-a784-9738b243e534",
   "metadata": {},
   "source": [
    "# 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f96cbb-37d3-49ae-a5f2-9e2de27eeea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(os.path.join(config.submission_data_dir, config.file_name), index=False)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51eb7a2-fba3-4a39-80bb-e7c262400f23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
