{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5d2c5c-0d38-4e02-bf3c-14e676c7bca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import gc\n",
    "import argparse\n",
    "import random\n",
    "from box import Box\n",
    "import cv2\n",
    "import cvlib as cv\n",
    "# import albumentations\n",
    "import timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3011f4f1-90cb-47fc-a042-5b4f73054027",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed 고정\n",
    "def seed_everything(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # if use multi-GPU\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a396c963-2529-4d80-89f0-c245b5aa3dc9",
   "metadata": {},
   "source": [
    "# 데이터 전처리 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0add8f5-dd45-4cf1-9b94-3536fd5d3261",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ages 생성\n",
    "def get_ages(x):\n",
    "    if x < 30: return 0\n",
    "    elif x < 60: return 1\n",
    "    else: return 2\n",
    "\n",
    "# genders 생성\n",
    "def get_genders(x):\n",
    "    if x == 'male': return 0\n",
    "    else: return 1\n",
    "\n",
    "# masks 생성\n",
    "def get_masks(x):\n",
    "    if x == 'normal': return 2\n",
    "    elif x == 'incorrect_mask': return 1\n",
    "    else: return 0\n",
    "\n",
    "# age_cats 생성\n",
    "def get_age_cats(x):\n",
    "    if x < 20: return 0\n",
    "    elif x < 30: return 1\n",
    "    elif x < 40: return 2\n",
    "    elif x < 50: return 3\n",
    "    elif x < 60: return 4\n",
    "    else: return 5\n",
    "\n",
    "# labels 생성\n",
    "def get_labels(masks, genders, ages):\n",
    "    return masks * 6 + genders * 3 + ages\n",
    "\n",
    "# label_cats 생성\n",
    "def get_label_cats(masks, genders, ages):\n",
    "    return masks * 12 + genders * 6 + ages\n",
    "\n",
    "# 마스크 이상치 변경\n",
    "def swap_mask(swap_li : list, df : pd.DataFrame) -> pd.DataFrame:\n",
    "    swap_df = df.copy()\n",
    "    for swap_id in swap_li:\n",
    "        _swap_df = swap_df[swap_df['id'] == swap_id]\n",
    "        \n",
    "        normal_swap_df = _swap_df[_swap_df['mask'] == 'normal']\n",
    "        incorrect_mask_swap_df = _swap_df[_swap_df['mask'] == 'incorrect_mask']\n",
    "        \n",
    "        normal_path = normal_swap_df['path'].values[0]\n",
    "        incorrect_mask_path = incorrect_mask_swap_df['path'].values[0]\n",
    "        \n",
    "        swap_df.loc[normal_swap_df.index, 'path'] = incorrect_mask_path\n",
    "        swap_df.loc[incorrect_mask_swap_df.index, 'path'] = normal_path\n",
    "    \n",
    "    return swap_df\n",
    "\n",
    "# train_df + mask 결측치 처리\n",
    "def make_train_df(df : pd.DataFrame, swap_mask_li : list, cfg) -> pd.DataFrame:\n",
    "    train_df = []\n",
    "    \n",
    "    for line in df.iloc:\n",
    "        for file in list(os.listdir(os.path.join(cfg.train_image_dir, line['path']))):\n",
    "            if file[0] == '.':\n",
    "                continue\n",
    "            \n",
    "            mask = file.split('.')[0]\n",
    "            gender = line['gender']\n",
    "            age = line['age']\n",
    "            \n",
    "            masks = get_masks(mask)\n",
    "            genders = get_genders(gender)\n",
    "            ages = get_ages(age)\n",
    "            age_cats = get_age_cats(age)\n",
    "            \n",
    "            data = {\n",
    "                'id' : line['id'],\n",
    "                'mask' : mask,\n",
    "                'gender' : gender,\n",
    "                'age' : age,\n",
    "                'masks' : masks,\n",
    "                'genders' : genders,\n",
    "                'ages' : ages,\n",
    "                'age_cats' : age_cats,\n",
    "                'labels': get_labels(masks = masks, genders = genders, ages = ages),\n",
    "                'label_cats': get_label_cats(masks = masks, genders = genders, ages = age_cats),\n",
    "                'path': os.path.join(cfg.train_image_dir, line['path'], file),\n",
    "            }\n",
    "            \n",
    "            train_df.append(data)\n",
    "            \n",
    "    train_df = pd.DataFrame(train_df)\n",
    "    \n",
    "    train_df['idx'] = train_df.index\n",
    "    train_df['transform'] = 0 # 적용할 transform 선택\n",
    "    \n",
    "    train_df = swap_mask(swap_li = swap_mask_li, df = train_df)\n",
    "    \n",
    "    return train_df\n",
    "\n",
    "# 성별 이상치 처리\n",
    "def swap_gender(swap_li : list, df : pd.DataFrame) -> pd.DataFrame:\n",
    "    swap_df = df.copy()\n",
    "    for swap in swap_li:\n",
    "        swap_id, swap_gender = swap\n",
    "        swap_df.loc[swap_df[swap_df['id'] == swap_id].index, 'gender'] = swap_gender\n",
    "    return swap_df\n",
    "\n",
    "# 사람 나누기 데이터 + 성별 결측치 처리\n",
    "def preprocessing_df(df : pd.DataFrame, swap_gender_li : list) -> pd.DataFrame:\n",
    "    \n",
    "    preprocessing_df = df.copy()\n",
    "    preprocessing_df = swap_gender(swap_li = swap_gender_li, df = preprocessing_df)\n",
    "    \n",
    "    preprocessing_df['ages'] = preprocessing_df['age'].apply(lambda x : get_ages(x))\n",
    "    preprocessing_df['genders'] = preprocessing_df['gender'].apply(lambda x : get_genders(x))\n",
    "    \n",
    "    preprocessing_df['cv_taget_col'] = 'ages' + '_' + preprocessing_df['ages'].astype(str) + '_' + 'genders' + '_' + preprocessing_df['genders'].astype(str)\n",
    "    \n",
    "    return preprocessing_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bac7f1e-a2a2-4058-aa9d-03f1be228c7b",
   "metadata": {},
   "source": [
    "# 오버샘플링 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67bb3793-f44a-4be7-916e-deb98fd9b8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_setting(train_df, sampling_list, target='labels'):\n",
    "    df = train_df.copy()\n",
    "\n",
    "    unsampling_df = df[~df[target].isin(sampling_list)]\n",
    "    unsampling_df.reset_index(drop = True, inplace = True)\n",
    "    \n",
    "#     row_size = len(unsampling_df)\n",
    "    \n",
    "#     unsampling_df['transform'] = pd.DataFrame(np.random.randint(0, 2, size=(row_size, 1)), columns=['transform'], dtype=np.int64)\n",
    "    unsampling_df['transform'] = 1\n",
    "    \n",
    "    return unsampling_df\n",
    "\n",
    "## 오버 샘플링\n",
    "\n",
    "def over_sampling(train_df, sampling_list, sampling_count_dict, target='labels'):\n",
    "    df = train_df.copy()\n",
    "    \n",
    "    df = df[df[target].isin(sampling_list)] \n",
    "    \n",
    "    sampling_df = pd.DataFrame()\n",
    "    \n",
    "    for key, value in sampling_count_dict.items():\n",
    "        temp_df = df[df[target] == key]\n",
    "        for count in range(value):\n",
    "            temp_df['transform'] = 1\n",
    "            sampling_df = pd.concat([sampling_df, temp_df], ignore_index=True)\n",
    "    \n",
    "    sampling_df.reset_index(drop = True, inplace = True)\n",
    "    \n",
    "    return sampling_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6466c6-37e1-4449-9a6d-bfef756b66d9",
   "metadata": {},
   "source": [
    "# 이상치 시각화 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8603a8a-baef-40cc-b809-57d25f065959",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이상치 이미지 시각화\n",
    "def show_img(img_id_li, df, cfg):\n",
    "    for img_id in img_id_li:\n",
    "        get_df = df[df['id'] == img_id]\n",
    "        \n",
    "        img_age = get_df['age'].tolist()[0]\n",
    "        img_gender = get_df['gender'].tolist()[0]\n",
    "        \n",
    "        img_path = get_df['path'].tolist()[0]\n",
    "        img_path = os.path.join(cfg.train_image_dir, img_path)\n",
    "        img_name_li = sorted(list(os.listdir(img_path)))\n",
    "        \n",
    "        fig, ax = plt.subplots(1, 7, figsize = (30, 15))\n",
    "        ax = ax.flatten()\n",
    "        \n",
    "        idx = 0\n",
    "        for _img_name in img_name_li:\n",
    "            if _img_name[0] == '.': continue\n",
    "            \n",
    "            if _img_name.split('.')[0] == 'normal': imag_name = 'normal'\n",
    "            elif _img_name.split('.')[0] == 'incorrect_mask': imag_name = 'incorrect_mask'\n",
    "            else: imag_name = 'mask'\n",
    "            \n",
    "            get_img_path = os.path.join(img_path, _img_name)\n",
    "            \n",
    "            img = Image.open(get_img_path)\n",
    "            img = np.array(img)\n",
    "            ax[idx].imshow(img)\n",
    "            ax[idx].set_title(f'{img_id} / {img_age} / {img_gender} / {imag_name}')\n",
    "            ax[idx].set_xticks([])\n",
    "            ax[idx].set_yticks([])\n",
    "            idx += 1\n",
    "            \n",
    "        plt.show()\n",
    "\n",
    "# image path로 이미지 시각화\n",
    "def path_li_show_img(path_li):\n",
    "    fig, ax = plt.subplots(1, 7, figsize = (30, 15))\n",
    "    ax = ax.flatten()\n",
    "    idx = 0\n",
    "    for path in path_li:\n",
    "        image_name = path.split('/')[-1]\n",
    "        img = Image.open(path)\n",
    "        img = np.array(img)\n",
    "        ax[idx].imshow(img)\n",
    "        ax[idx].set_title(f'{image_name}')\n",
    "        ax[idx].set_xticks([])\n",
    "        ax[idx].set_yticks([])\n",
    "        idx += 1\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62553119-8862-4f1f-bdd5-5da4de1a0a45",
   "metadata": {},
   "source": [
    "# 데이터 설정 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44405254-ea08-48ba-9396-1ee689f0b786",
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_idx 생성\n",
    "def get_val_idx(df : pd.DataFrame, target_col : str):\n",
    "    skf = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 22)\n",
    "    for trn_idx, val_idx in skf.split(df, df[target_col]):\n",
    "        yield val_idx\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, df : pd.DataFrame, cfg, transform_list : list, mode : bool = True):\n",
    "        self.mode = mode\n",
    "        self.df = df\n",
    "        if self.mode:\n",
    "            self.img_paths = self.df['path'].tolist()\n",
    "            self.targets = self.df[cfg.tagets_col].tolist()\n",
    "            self.split_targets = self.df[cfg.split_col].tolist()\n",
    "            self.transform_idx = self.df['transform'].tolist()\n",
    "        else:\n",
    "            self.img_paths = [os.path.join(cfg.submission_image_dir, img_id) for img_id in self.df.ImageID]\n",
    "        self.transform = transform_list\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = Image.open(self.img_paths[index])\n",
    "        \n",
    "        if self.transform:\n",
    "#             image = self.transform(image = np.array(image))['image']\n",
    "            image = self.transform[0](image)\n",
    "    \n",
    "        # 이 부분에 해당 라벨에 따른 데이터 변환 여부 추가\n",
    "        # val 데이터의 경우 데이터 변환이 일어나면 안되기 때문에\n",
    "        # if self.데이터 변환해주는 transform:\n",
    "        #     if self.targets[index].data == labels: <- 확률적으로\n",
    "        #          image = self.데이터 변환해주는 transform(image)\n",
    "        # 데이터 변환\n",
    "        \n",
    "        if self.mode:\n",
    "            if self.transform_idx[index] != 0:\n",
    "                image = self.transform[self.transform_idx[index]](image)\n",
    "                \n",
    "            targets = torch.tensor(self.targets[index])\n",
    "            return image, targets\n",
    "        \n",
    "        else: return image\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)\n",
    "\n",
    "class StratifiedSampler(torch.utils.data.Sampler):\n",
    "    \"\"\"Stratified batch sampling\n",
    "    Provides equal representation of target classes in each batch\n",
    "    \"\"\"\n",
    "    def __init__(self, y, batch_size, shuffle=True):\n",
    "        if torch.is_tensor(y):\n",
    "            y = y.cpu().numpy()\n",
    "        assert len(y.shape) == 1, 'label array must be 1D'\n",
    "        n_batches = int(len(y) / batch_size)\n",
    "        self.skf = StratifiedKFold(n_splits = n_batches, shuffle = shuffle)\n",
    "        self.X = torch.randn(len(y),1).numpy()\n",
    "        self.y = y\n",
    "        self.shuffle = shuffle\n",
    "\n",
    "    def __iter__(self):\n",
    "        if self.shuffle:\n",
    "            self.skf.random_state = torch.randint(0,int(1e8),size=()).item()\n",
    "        for train_idx, test_idx in self.skf.split(self.X, self.y):\n",
    "            yield test_idx\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "931c23a0-236a-4bed-9106-6c321c86f9af",
   "metadata": {},
   "source": [
    "# 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a50293-f658-432a-a858-5036b9593c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CreateModel(nn.Module):\n",
    "    def __init__(self, cfg , pretrained : bool = True):\n",
    "        super(CreateModel, self).__init__()\n",
    "        self.model = timm.create_model(cfg.timm_model_name, pretrained = pretrained, num_classes = cfg.num_classes)\n",
    "\n",
    "    def forward(self, img):\n",
    "        out = self.model(img)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5304af28-ee28-4383-a06d-0deb10ecd89a",
   "metadata": {},
   "source": [
    "# 스코어 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc2534a-83ba-42f8-99a6-0a421bfaad7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_f1_score(y_true, y_pred):\n",
    "    return f1_score(y_true, y_pred, average='macro')\n",
    "\n",
    "def get_acc_score(y_true, y_pred):\n",
    "    return accuracy_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2159e73-219e-4a6b-ab16-5a927be48725",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_train(model, optimizer, criterion, data_loader):\n",
    "    model.train()\n",
    "    \n",
    "    train_loss = 0\n",
    "    real_pred_li = []\n",
    "    label_pred_li = []\n",
    "    \n",
    "    for images, targets in data_loader:\n",
    "        images, targets = images.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # GA 추가시 아래 부분에 추가하기\n",
    "        #############################\n",
    "        \n",
    "        benign_outputs = model(images)\n",
    "        loss = criterion(benign_outputs, targets)\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        predicted = benign_outputs.argmax(dim=-1)\n",
    "        \n",
    "        label_pred_li.extend(predicted.detach().cpu().numpy())\n",
    "        real_pred_li.extend(targets.cpu().numpy())\n",
    "        \n",
    "#     label_pred_li = [label_cats2labels[i] for i in label_pred_li]\n",
    "#     real_pred_li = [label_cats2labels[i] for i in real_pred_li]\n",
    "    \n",
    "    train_loss /= len(data_loader)\n",
    "    train_acc = get_acc_score(y_true = real_pred_li, y_pred = label_pred_li)\n",
    "    train_fi_score = get_f1_score(y_true = real_pred_li, y_pred = label_pred_li)\n",
    "\n",
    "    return train_loss, train_acc, train_fi_score\n",
    "\n",
    "def model_eval(model, criterion, data_loader):\n",
    "    model.eval()\n",
    "    \n",
    "    val_loss = 0\n",
    "    real_pred_li = []\n",
    "    label_pred_li = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, targets in data_loader:\n",
    "            images, targets = images.to(device), targets.to(device)\n",
    "\n",
    "            benign_outputs = model(images)\n",
    "            loss = criterion(benign_outputs, targets)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            predicted = benign_outputs.argmax(dim=-1)\n",
    "        \n",
    "            label_pred_li.extend(predicted.cpu().numpy())\n",
    "            real_pred_li.extend(targets.cpu().numpy())\n",
    "    \n",
    "#     label_pred_li = [label_cats2labels[i] for i in label_pred_li]\n",
    "#     real_pred_li = [label_cats2labels[i] for i in real_pred_li]\n",
    "    \n",
    "    val_loss /= len(data_loader)\n",
    "    val_acc = get_acc_score(y_true = real_pred_li, y_pred = label_pred_li)\n",
    "    val_fi_score = get_f1_score(y_true = real_pred_li, y_pred = label_pred_li)\n",
    "   \n",
    "    return val_loss, val_acc, val_fi_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b3b262-1703-4583-a937-28c5db3bb5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9b38e3-426b-4f06-b500-e3631320aac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_val_pred_li(model, data_loader):\n",
    "    model.eval()\n",
    "    real_pred_li = []\n",
    "    label_pred_li = []\n",
    "    ensemble_pred_li = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, targets in data_loader:\n",
    "            images = images.to(device)\n",
    "            output = model(images)\n",
    "            \n",
    "            label = output.argmax(dim=-1)\n",
    "            label_pred_li.extend(label.cpu().numpy())\n",
    "            \n",
    "            ensemble_label = output.softmax(1)\n",
    "            ensemble_pred_li.append(ensemble_label.cpu().numpy())\n",
    "            \n",
    "            real_pred_li.extend(targets.cpu().numpy())\n",
    "            \n",
    "#     label_pred_li = [label_cats2labels[i] for i in label_pred_li]\n",
    "#     real_pred_li = [label_cats2labels[i] for i in real_pred_li]\n",
    "    \n",
    "    return label_pred_li, np.concatenate(ensemble_pred_li), real_pred_li\n",
    "\n",
    "def get_submission_pred_li(model, data_loader):\n",
    "    model.eval()\n",
    "    label_pred_li = []\n",
    "    ensemble_pred_li = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images in data_loader:\n",
    "            images = images.to(device)\n",
    "            output = model(images)\n",
    "            \n",
    "            label = output.argmax(dim=-1)\n",
    "            label_pred_li.extend(label.cpu().numpy())\n",
    "            \n",
    "            ensemble_label = output.softmax(1)\n",
    "            ensemble_pred_li.append(ensemble_label.cpu().numpy())\n",
    "            \n",
    "#     label_pred_li = [label_cats2labels[i] for i in label_pred_li]\n",
    "    \n",
    "    return label_pred_li, np.concatenate(ensemble_pred_li)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aefc2e44-fedf-4a9c-8e71-ea8f077bf8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, weight=None, gamma=2., reduction='mean'):\n",
    "        nn.Module.__init__(self)\n",
    "        self.weight = weight\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, input_tensor, target_tensor):\n",
    "        log_prob = F.log_softmax(input_tensor, dim=-1)\n",
    "        prob = torch.exp(log_prob)\n",
    "        return F.nll_loss(\n",
    "            ((1 - prob) ** self.gamma) * log_prob,\n",
    "            target_tensor,\n",
    "            weight=self.weight,\n",
    "            reduction=self.reduction\n",
    "        )\n",
    "\n",
    "\n",
    "class LabelSmoothingLoss(nn.Module):\n",
    "    def __init__(self, classes=3, smoothing=0.0, dim=-1):\n",
    "        super(LabelSmoothingLoss, self).__init__()\n",
    "        self.confidence = 1.0 - smoothing\n",
    "        self.smoothing = smoothing\n",
    "        self.cls = classes\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, pred, target):\n",
    "        pred = pred.log_softmax(dim=self.dim)\n",
    "        with torch.no_grad():\n",
    "            true_dist = torch.zeros_like(pred)\n",
    "            true_dist.fill_(self.smoothing / (self.cls - 1))\n",
    "            true_dist.scatter_(1, target.data.unsqueeze(1), self.confidence)\n",
    "        return torch.mean(torch.sum(-true_dist * pred, dim=self.dim))\n",
    "\n",
    "\n",
    "# https://gist.github.com/SuperShinyEyes/dcc68a08ff8b615442e3bc6a9b55a354\n",
    "class F1Loss(nn.Module):\n",
    "    def __init__(self, classes=3, epsilon=1e-7):\n",
    "        super().__init__()\n",
    "        self.classes = classes\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "        assert y_pred.ndim == 2\n",
    "        assert y_true.ndim == 1\n",
    "        y_true = F.one_hot(y_true, self.classes).to(torch.float32)\n",
    "        y_pred = F.softmax(y_pred, dim=1)\n",
    "\n",
    "        tp = (y_true * y_pred).sum(dim=0).to(torch.float32)\n",
    "        tn = ((1 - y_true) * (1 - y_pred)).sum(dim=0).to(torch.float32)\n",
    "        fp = ((1 - y_true) * y_pred).sum(dim=0).to(torch.float32)\n",
    "        fn = (y_true * (1 - y_pred)).sum(dim=0).to(torch.float32)\n",
    "\n",
    "        precision = tp / (tp + fp + self.epsilon)\n",
    "        recall = tp / (tp + fn + self.epsilon)\n",
    "\n",
    "        f1 = 2 * (precision * recall) / (precision + recall + self.epsilon)\n",
    "        f1 = f1.clamp(min=self.epsilon, max=1 - self.epsilon)\n",
    "        return 1 - f1.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892bc074-57cc-4c87-bb82-20936b25b1cb",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 환경 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac961a79-bcba-46d4-bcc4-435ce0cf453e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이상치 list\n",
    "# swap_gender_li = ['id', '바꿀 성별']\n",
    "# swap_mask_li = ['id']\n",
    "swap_gender_li = [['006359', 'male'], ['006360', 'male'], ['006361', 'male'], ['006362', 'male'], \n",
    "                  ['006363', 'male'], ['006364', 'male'], ['001498-1', 'female'], ['004432', 'female']]\n",
    "swap_mask_li = ['000020', '004418', '005227']\n",
    "\n",
    "config = {\n",
    "    'seed' : 22,\n",
    "    \n",
    "    'image_size' : [512, 384],\n",
    "    'image_normal_mean' : [0.485, 0.456, 0.406],\n",
    "    'image_normal_std' : [0.229, 0.224, 0.225],\n",
    "    \n",
    "    # oversampling\n",
    "    'sampling_target' : 'labels',\n",
    "    'sampling_list' : [2, 5] + [i for i in range(6, 18)], \n",
    "    'sampling_count' : {2 : 4, 5 : 3, 6 : 3, 7: 4, 8: 20, 9 : 2, 10 : 2, 11 : 13\n",
    "                      , 12 : 3, 13 : 4, 14 : 20, 15 : 2, 16 : 2, 17 : 13},\n",
    "    'transform_p' : 0.7,\n",
    "    \n",
    "    'crop_size' : 384,\n",
    "    'blur_kernel_size' : (5, 9),\n",
    "    'blur_sigma' : (0.1, 5),\n",
    "    'brightness' : 0.5,\n",
    "    'hue' : 0.3,\n",
    "    'rotation' : 10,\n",
    "    \n",
    "    'num_workers' : 3,\n",
    "    'epochs' : 30,\n",
    "    'batch_size' : 128,\n",
    "    'lr' : 0.00001,\n",
    "    'oof' : 1,\n",
    "    'num_classes' : 3,\n",
    "    \n",
    "#     cel\n",
    "#     labelsmoothing\n",
    "#     focal\n",
    "#     f1\n",
    "    'loss' : 'labelsmoothing',\n",
    "    'smoothing' : 0.1,\n",
    "    \n",
    "    'train_data_name' : 'train.csv',\n",
    "    'train_data_dir' : '/opt/ml/input/data/train',\n",
    "    'train_image_dir' : '/opt/ml/input/data/train/images',\n",
    "    \n",
    "    'submission_data_name' : 'info.csv',\n",
    "    'submission_data_dir' : '/opt/ml/input/data/eval',\n",
    "    'submission_image_dir' : '/opt/ml/input/data/eval/images',\n",
    "    'submission_dir' : './submission',\n",
    "    \n",
    "    \n",
    "    'model_dir' : './model',\n",
    "    # 저장할 모델병\n",
    "    'model_name' : 'regnety_002_v28',\n",
    "    \n",
    "    # timm 에 존재하는 모델 이름\n",
    "    'timm_model_name' : 'regnety_002',\n",
    "    \n",
    "    # 학습 타겟\n",
    "    'tagets_col' : 'ages',\n",
    "    'split_col' : 'label_cats',\n",
    "    'cv_taget_col' : 'cv_taget_col',\n",
    "    \n",
    "    # 저장할 파일명\n",
    "    'file_name' : 'regnety_002_v28.csv',\n",
    "}\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "config = Box(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf47fce1-02a4-4a69-9611-222414bf7fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 변환할 transform\n",
    "# from albumentations import *\n",
    "# from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "def image_face_crop(image, **kwargs):\n",
    "    face, confidence = cv.detect_face(image)\n",
    "    if not face : return image\n",
    "    x, y, w, h = face[0]\n",
    "    H, W, C = image.shape\n",
    "    image = image[max(y - 100, 0) : min(h + 100, H), max(0 , x - 100) : min(w + 100, W)]\n",
    "    return image\n",
    "\n",
    "# 적용할 transform 목록 정의\n",
    "transform_list = [\n",
    "    transforms.Compose([\n",
    "#     Resize(image_size, Image.BILINEAR),\n",
    "    transforms.ToTensor(),\n",
    "#     transforms.CenterCrop(config.crop_size),\n",
    "    transforms.Normalize(mean=config.image_normal_mean, std=config.image_normal_std),\n",
    "#     transforms.Grayscale(num_output_channels=3),\n",
    "]),\n",
    "    \n",
    "    transforms.Compose([\n",
    "    transforms.RandomApply(transforms = [transforms.ColorJitter(brightness=config.brightness, hue=config.hue)], p = config.transform_p),\n",
    "    transforms.RandomApply(transforms = [transforms.GaussianBlur(kernel_size = config.blur_kernel_size, sigma = config.blur_sigma)], p = config.transform_p),\n",
    "    transforms.RandomHorizontalFlip(p = config.transform_p),\n",
    "#     transforms.RandomApply(transforms = [transforms.Grayscale(num_output_channels=3)], p = config.transform_p),\n",
    "])\n",
    "        \n",
    "             \n",
    "]\n",
    "\n",
    "# transform = {\n",
    "#         \"train\": transforms.Compose(\n",
    "#             [\n",
    "# #                 Lambda(image_face_crop),\n",
    "# #                 ToPILImage(),\n",
    "#                 Resize(config.image_size, Image.BILINEAR),\n",
    "#                 ToTensor(),\n",
    "# #                 RandomHorizontalFlip(p = 0.5),\n",
    "#                 Normalize(mean=config.image_normal_mean, std=config.image_normal_std),\n",
    "#             ]\n",
    "#         ),  \n",
    "#         \"val\": transforms.Compose(\n",
    "#             [\n",
    "#                 Resize(config.image_size, Image.BILINEAR),\n",
    "#                 ToTensor(),\n",
    "#                 Normalize(mean=config.image_normal_mean, std=config.image_normal_std),\n",
    "#             ]\n",
    "#         ),\n",
    "#     }\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1966b7e-b676-41fe-a0aa-bf6d233824c6",
   "metadata": {},
   "source": [
    "# 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9bfae8-4bda-4749-949b-e3389a6fed43",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(config.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01270fba-3558-42dc-81e9-e5574e6c963a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(config.train_data_dir, config.train_data_name))\n",
    "submission = pd.read_csv(os.path.join(config.submission_data_dir, config.submission_data_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52932149-7935-4bd5-92bf-1f706d951914",
   "metadata": {},
   "source": [
    "# 이상치 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13d2daf-b3a7-442e-9d94-16c8d6b96321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_img(img_id_li =['000020', '004418', '005227', '006359', '006360', '006361', '006362', '006363', '006364', '001498-1'], df = df, cfg = config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c589239-662f-4af2-add9-7648b8c77a68",
   "metadata": {},
   "source": [
    "# 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45fb0b8e-eff7-4ace-abce-7e882e9d84d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_df = preprocessing_df(df = df, swap_gender_li = swap_gender_li)\n",
    "train_df = make_train_df(df = pre_df, swap_mask_li = swap_mask_li, cfg = config)\n",
    "\n",
    "all_idx_li = pre_df.index.tolist()\n",
    "val_idx_li = get_val_idx(df = pre_df, target_col = config.cv_taget_col)\n",
    "\n",
    "total_start_time = time.time()\n",
    "\n",
    "for fold_num in range(1, config.oof + 1):\n",
    "    fold_start_time = time.time()\n",
    "    \n",
    "    # trn, val 데이터 셋\n",
    "    val_idx = next(val_idx_li)\n",
    "    trn_idx = list(set(all_idx_li) - set(val_idx.tolist()))\n",
    "    \n",
    "    val_id_df = pre_df.iloc[val_idx, :]\n",
    "    trn_id_df = pre_df.iloc[trn_idx, :]\n",
    "    \n",
    "    val_df = train_df.set_index('id').loc[val_id_df['id'].tolist(), :].reset_index()\n",
    "    trn_df = train_df.set_index('id').loc[trn_id_df['id'].tolist(), :].reset_index()\n",
    "    # 이 부분에 클래스가 적은 데이터 증강 함수 추가\n",
    "    ########################################3\n",
    "    \n",
    "\n",
    "    unsampling_set = transform_setting(trn_df, sampling_list = config.sampling_list, target = config.sampling_target)\n",
    "    \n",
    "    sampling_set = over_sampling(trn_df, sampling_list = config.sampling_list, sampling_count_dict = config.sampling_count, target = config.sampling_target)\n",
    "    \n",
    "    trn_df = pd.concat([unsampling_set, sampling_set], ignore_index=True)\n",
    "\n",
    "    # 배치 단위 데이터 생성 부분\n",
    "    #########################\n",
    "    \n",
    "    \n",
    "    # dataset 구축\n",
    "    trn_dataset = CustomDataset(df = trn_df,\n",
    "                                cfg = config,\n",
    "                                transform_list = transform_list,\n",
    "                                mode = True,\n",
    "                               )\n",
    "    \n",
    "    train_loder = DataLoader(trn_dataset,\n",
    "                           batch_size = config.batch_size,\n",
    "                           num_workers = config.num_workers,\n",
    "                           shuffle = True,\n",
    "                            )\n",
    "    \n",
    "    \n",
    "#     sampler = StratifiedSampler(y = np.array(trn_dataset.split_targets), \n",
    "#                                 batch_size = config.batch_size, \n",
    "#                                 shuffle = True)\n",
    "    \n",
    "#     train_loder = DataLoader(trn_dataset,\n",
    "#                              num_workers = config.num_workers,\n",
    "#                              batch_sampler = sampler)\n",
    "    \n",
    "    \n",
    "    val_dataset = CustomDataset(df = val_df,\n",
    "                                cfg = config,\n",
    "                                transform_list = transform_list,\n",
    "                                mode = True,)\n",
    "    \n",
    "    val_loder = DataLoader(val_dataset,\n",
    "                           batch_size = config.batch_size,\n",
    "                           num_workers = config.num_workers,\n",
    "                           shuffle = False,)\n",
    "    \n",
    "    # 모델 정의\n",
    "    model = CreateModel(cfg = config, pretrained = True).to(device)\n",
    "\n",
    "    # loss 설정\n",
    "    if config.loss == 'cel':\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "    elif config.loss == 'labelsmoothing':\n",
    "        criterion = LabelSmoothingLoss(classes=config.num_classes, smoothing = config.smoothing, dim=-1)\n",
    "    elif config.loss == 'focal':\n",
    "        criterion = FocalLoss(weight=None, gamma=2., reduction='mean')\n",
    "    elif config.loss == 'f1':\n",
    "        criterion = F1Loss(classes=config.num_classes, epsilon=1e-7)\n",
    "    else:\n",
    "        print('not loss')\n",
    "    \n",
    "    # optimizer 설정\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=config.lr, amsgrad=True)\n",
    "    \n",
    "    # scheduler 설정\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor = 0.1, eps = 1e-09, patience = 5)\n",
    "   \n",
    "    # besf_metric 설정\n",
    "    min_val_loss = float(\"inf\")\n",
    "    early_stopping_count = 0\n",
    "    \n",
    "    for epoch in tqdm(range(1, config.epochs + 1)):\n",
    "        epoch_start_time = time.time()\n",
    "        \n",
    "        train_loss, train_acc, train_fi_score = model_train(model = model, \n",
    "                                                            optimizer = optimizer, \n",
    "                                                            criterion = criterion, \n",
    "                                                            data_loader = train_loder)\n",
    "        \n",
    "        val_loss, val_acc, val_fi_score, = model_eval(model = model,\n",
    "                                                      criterion = criterion,\n",
    "                                                      data_loader = val_loder)\n",
    "        \n",
    "        # 학습률\n",
    "        now_lr = get_lr(optimizer = optimizer)\n",
    "        \n",
    "        epoch_end_time = time.time()\n",
    "        \n",
    "        print(f'''{fold_num}fold, epoch: {epoch}, lr: {now_lr}, train_loss: {train_loss:.4f}, train_acc: {train_acc:.4f}, train_f1: {train_fi_score:.4f}, val_loss: {val_loss:.4f}, val_acc: {val_acc:.4f}, val_fi: {val_fi_score:.4f}, 학습시간: {epoch_end_time - epoch_start_time} \\n''')\n",
    "\n",
    "        # 스케줄러\n",
    "        scheduler.step(val_loss)\n",
    "        \n",
    "        # 모델 저장\n",
    "        if val_loss < min_val_loss:\n",
    "            min_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), os.path.join(config.model_dir, f'{fold_num}fold_{config.model_name}.pt'))\n",
    "            print(val_loss, '모델 저장')\n",
    "            early_stopping_count = 0\n",
    "        else:\n",
    "            early_stopping_count += 1\n",
    "            if early_stopping_count == 10:\n",
    "                print('early_stopping')\n",
    "                break\n",
    "            \n",
    "        # 모델 저장\n",
    "#         if besf_fi < val_loss:\n",
    "#             besf_fi = val_fi_score\n",
    "#             torch.save(model.state_dict(), os.path.join(config.model_dir, f'{fold_num}fold_{config.model_name}.pt'))\n",
    "#             print(besf_fi, '모델 저장')\n",
    "    \n",
    "    fold_end_time = time.time()\n",
    "    \n",
    "    print(f'{fold_num}fold 훈련 시간: {fold_end_time - fold_start_time} \\n')\n",
    "    \n",
    "    # 메모리 정리\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "total_end_time = time.time()\n",
    "print(f'총 훈련 시간: {total_end_time - total_start_time}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aee6d31-3204-4d9c-b096-dd3973f04ca7",
   "metadata": {},
   "source": [
    "# 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631ce276-82eb-4b71-b87e-d78e7ff584be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# submission 데이터 정의\n",
    "submission_dataset = CustomDataset(df = submission, \n",
    "                                   cfg = config,\n",
    "                                   transform_list = transform_list,\n",
    "                                   mode = False,\n",
    "                                  )\n",
    "\n",
    "submission_loder = DataLoader(submission_dataset,\n",
    "                                batch_size = config.batch_size,\n",
    "                                num_workers = config.num_workers,\n",
    "                                shuffle = False,\n",
    "                             )\n",
    "\n",
    "submission_label_oof = np.zeros((submission.shape[0], config.num_classes))\n",
    "\n",
    "pre_df = preprocessing_df(df = df, swap_gender_li = swap_gender_li)\n",
    "train_df = make_train_df(df = pre_df, swap_mask_li = swap_mask_li, cfg = config)\n",
    "\n",
    "all_idx_li = pre_df.index.tolist()\n",
    "val_idx_li = get_val_idx(df = pre_df, target_col = config.cv_taget_col)\n",
    "\n",
    "real_labels = []\n",
    "pred_labels = []\n",
    "idx_li = []\n",
    "\n",
    "for fold_num in tqdm(range(1, config.oof + 1)):\n",
    "    fold_start_time = time.time()\n",
    "    \n",
    "    # val\n",
    "    val_idx = next(val_idx_li)\n",
    "    trn_idx = list(set(all_idx_li) - set(val_idx.tolist()))\n",
    "    \n",
    "    val_id_df = pre_df.iloc[val_idx, :]\n",
    "    trn_id_df = pre_df.iloc[trn_idx, :]\n",
    "    \n",
    "    val_df = train_df.set_index('id').loc[val_id_df['id'].tolist(), :].reset_index()\n",
    "    trn_df = train_df.set_index('id').loc[trn_id_df['id'].tolist(), :].reset_index()\n",
    "    \n",
    "    val_dataset = CustomDataset(df = val_df, \n",
    "                                cfg = config,\n",
    "                                transform_list = transform_list,\n",
    "                                mode = True,\n",
    "                               )\n",
    "    \n",
    "    val_loder = DataLoader(val_dataset,\n",
    "                            batch_size = config.batch_size,\n",
    "                           num_workers = config.num_workers,\n",
    "                            shuffle = False,)\n",
    "    \n",
    "    # 모델 로드\n",
    "    model = CreateModel(cfg = config, pretrained = False).to(device)\n",
    "    model.load_state_dict(torch.load(os.path.join(config.model_dir, f'{fold_num}fold_{config.model_name}.pt')))\n",
    "    \n",
    "    # val 평가\n",
    "    val_label_pred_li, val_ensemble_pred_li, real_pred_li = get_val_pred_li(model = model, data_loader = val_loder)\n",
    "    \n",
    "    real_labels += real_pred_li\n",
    "    pred_labels += val_label_pred_li\n",
    "    idx_li += val_df['idx'].tolist()\n",
    "    \n",
    "    # submission 평가\n",
    "    submission_label_pred_li, submission_ensemble_pred_li = get_submission_pred_li(model = model, data_loader = submission_loder)\n",
    "    submission_label_oof += submission_ensemble_pred_li / config.oof\n",
    "    \n",
    "    fold_end_time = time.time()\n",
    "\n",
    "    _acc = get_acc_score(y_true = real_pred_li, y_pred = val_label_pred_li)\n",
    "    _f1_score = get_f1_score(y_true = real_pred_li, y_pred = val_label_pred_li)\n",
    "\n",
    "    print(f'{fold_num}fold 훈련 시간: {fold_end_time - fold_start_time}, acc: {_acc}, f1_score: {_f1_score} \\n')\n",
    "\n",
    "# pred_li = submission_label_oof.argmax(1).tolist()\n",
    "# pred_li = [label_cats2labels[i] for i in pred_li]\n",
    "# submission['ans'] = pred_li\n",
    "\n",
    "submission['ans'] = submission_label_oof.argmax(1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923f7868-49c2-44ab-82a1-38d8663ef503",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_label_oof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927a705d-a143-4637-a7aa-bed380bbae5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c953d8-b715-4b02-a4ea-c52abaec0c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['ans'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9748bca-16fb-4620-9ba6-04f9921e45fe",
   "metadata": {},
   "source": [
    "## Age_Cats to Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3cb25c-f176-4101-9ca9-7aaac603f4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# submission age target 변경\n",
    "def age_cats_to_target(x):\n",
    "    if x <= 1: return 0\n",
    "    elif x <= 4: return 1\n",
    "    else: return 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a38fa8-fda9-4930-81d1-c2d062460760",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['ans'] = submission['ans'].apply(age_cats_to_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d8f939-fa24-47b8-a299-46b28e2604b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['ans'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b087a77c-e268-4447-832f-478331f2a4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30dc6c8c-71cf-4efc-9ddb-be399c73b230",
   "metadata": {},
   "source": [
    "# 결과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33653a37-8493-4d97-af37-0f1f546ab109",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_f1 = get_f1_score(y_true = real_labels, y_pred = pred_labels)\n",
    "train_acc = get_acc_score(y_true = real_labels, y_pred = pred_labels)\n",
    "train_confusion_matrix = pd.DataFrame((confusion_matrix(y_true = real_labels, y_pred = pred_labels)))\n",
    "print(f'train confusion_matrix')\n",
    "display(train_confusion_matrix.style.background_gradient(cmap='YlOrRd', axis = 1))\n",
    "print(f'train fi : {train_f1:.4f}, train acc: {train_acc:.4f} \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dbd9608-13c6-4866-bce9-309ce4387da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels 로 masks, genders, ages 역추적\n",
    "labels2masks_genders_ages = {}\n",
    "for line in train_df[~(train_df.duplicated(subset=[config.tagets_col]))].iloc:\n",
    "    labels2masks_genders_ages[line[config.tagets_col]] = str(line['masks']) + '-' + str(line['genders']) + '-' + str(line['ages'])\n",
    "\n",
    "# 틀린 이미지 시각화\n",
    "image_show_df = train_df.iloc[idx_li, :].reset_index(drop =True)\n",
    "image_show_df['pred_labels'] = pred_labels\n",
    "false_image_show_df = image_show_df[image_show_df[config.tagets_col] != image_show_df['pred_labels']]\n",
    "labels_li = [i for i in range(config.num_classes)]\n",
    "for labels in labels_li:\n",
    "    _false_image_show_df = false_image_show_df[false_image_show_df[config.tagets_col] == labels]\n",
    "    path_labels_pred_labels_li = _false_image_show_df[['path', config.tagets_col, 'pred_labels']].values[:7]\n",
    "    \n",
    "    idx = 0\n",
    "    fig, ax = plt.subplots(1, 7, figsize = (30, 15))\n",
    "    ax = ax.flatten()\n",
    "    for path_labels_pred_labels in path_labels_pred_labels_li:\n",
    "        img = Image.open(path_labels_pred_labels[0])\n",
    "        img = np.array(img)\n",
    "        ax[idx].imshow(img)\n",
    "        ax[idx].set_title(f'true {path_labels_pred_labels[1]} - {labels2masks_genders_ages[path_labels_pred_labels[1]]} / pred {path_labels_pred_labels[2]} - {labels2masks_genders_ages[path_labels_pred_labels[2]]} ')\n",
    "        ax[idx].set_xticks([])\n",
    "        ax[idx].set_yticks([])\n",
    "        idx += 1\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7fb98b-f23a-4f39-b416-e1d2e956bc7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "61a4b84b-969f-4c34-a784-9738b243e534",
   "metadata": {},
   "source": [
    "# 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f96cbb-37d3-49ae-a5f2-9e2de27eeea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(os.path.join(config.submission_dir, config.file_name), index=False)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6431e88-c38e-4606-880c-4e1c51acc22c",
   "metadata": {},
   "source": [
    "# 앙상블"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a7c1fa-7caf-4528-b054-bc4eedb2ee29",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame()\n",
    "pred_df['masks'] = pred_labels\n",
    "pred_df.to_csv(os.path.join(config.submission_dir, f'{config.timm_model_name}_masks.csv'))\n",
    "pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa49742-5bb7-40de-8297-4fff5a344f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_ages_df = pd.read_csv(os.path.join(config.submission_dir, f'{config.timm_model_name}_ages.csv'))\n",
    "pred_genders_df = pd.read_csv(os.path.join(config.submission_dir, f'{config.timm_model_name}_genders.csv'))\n",
    "pred_masks_df = pd.read_csv(os.path.join(config.submission_dir, f'{config.timm_model_name}_masks.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db9b94b-8d7f-4d39-962f-7ef8dadc0c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels(masks, genders, ages):\n",
    "    return masks * 6 + genders * 3 + ages\n",
    "\n",
    "pred_li = []\n",
    "for masks_line, genders_line, ages_line in zip(pred_masks_df.iloc, pred_genders_df.iloc, pred_ages_df.iloc):\n",
    "    pred_li.append(get_labels(masks_line['masks'], genders_line['genders'], ages_line['ages']))\n",
    "\n",
    "pred_df = pd.DataFrame()\n",
    "pred_df['labels'] = pred_li"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d632ea-d47b-4fe3-b81d-5d76b50d2415",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_labels = train_df.iloc[idx_li, :].reset_index(drop =True)['labels'].tolist()\n",
    "pred_labels = pred_df['labels'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc0c082-30a0-4cd0-80ff-dafcb4b15b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_f1 = get_f1_score(y_true = real_labels, y_pred = pred_labels)\n",
    "train_acc = get_acc_score(y_true = real_labels, y_pred = pred_labels)\n",
    "train_confusion_matrix = pd.DataFrame((confusion_matrix(y_true = real_labels, y_pred = pred_labels)))\n",
    "print(f'train confusion_matrix')\n",
    "display(train_confusion_matrix.style.background_gradient(cmap='YlOrRd', axis = 1))\n",
    "print(f'train fi : {train_f1:.4f}, train acc: {train_acc:.4f} \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc3caec-9e91-44ae-9cfc-dcfc92f1b7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.submission_data_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38465d1c-39bd-4dbf-8938-4f9d656d2224",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = pd.read_csv(os.path.join(config.submission_dir, config.submission_data_name))\n",
    "sub_ages_df = pd.read_csv(os.path.join(config.submission_dir, f'{config.timm_model_name}_ages.csv'))\n",
    "sub_genders_df = pd.read_csv(os.path.join(config.submission_dir, f'{config.timm_model_name}_genders.csv'))\n",
    "sub_masks_df = pd.read_csv(os.path.join(config.submission_dir, f'{config.timm_model_name}_masks.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4724b49c-be44-40e0-bff4-09de8c201140",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels(masks, genders, ages):\n",
    "    return masks * 6 + genders * 3 + ages\n",
    "\n",
    "pred_li = []\n",
    "for masks_line, genders_line, ages_line in zip(sub_masks_df.iloc, sub_genders_df.iloc, sub_ages_df.iloc):\n",
    "    pred_li.append(get_labels(masks_line['ans'], genders_line['ans'], ages_line['ans']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89eb578-b11b-480f-b444-923ab2569cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df['ans'] = pred_li"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641468ce-82c1-4781-903d-fcf19c883f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.to_csv(os.path.join(config.submission_dir, 'ages_genders_masks_ensemble.csv'), index=False)\n",
    "submission_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b81e45b-7120-4db5-bdab-826bcf935d11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
