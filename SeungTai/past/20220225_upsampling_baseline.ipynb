{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2484966d-3666-4b58-89d6-de35384fe84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import glob\n",
    "import shutil\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 모델 관련 모듈\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import Resize, ToTensor, Normalize\n",
    "import torchvision.models as models\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c62f87-667b-4136-abd8-5c31d716b50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 경로 설정\n",
    "\n",
    "data_dir = '../input/data/train/'\n",
    "test_dir = '../input/data/eval/'\n",
    "submission_dir = './submission/'\n",
    "submission_image_dir = '../input/data/eval/images'\n",
    "model_dir = './model/'\n",
    "train_image_dir = data_dir + 'images/'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "289d4d39-f938-408f-9c90-98d91617ea72",
   "metadata": {},
   "source": [
    "## Seed 고정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed7fa41-1010-4e33-b496-2593661e8a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "정인식님 코드 참고\n",
    "\n",
    "'''\n",
    "\n",
    "random_seed = 42\n",
    "\n",
    "#pytorch의 random seed 고정\n",
    "\n",
    "torch.manual_seed(random_seed)\n",
    "\n",
    "# CuDNN 부분고정\n",
    "\n",
    "torch.backends.cudnn.deterministic = True # 고정하면 학습이 느려진다고 합니다.\n",
    "\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Numpy 부분\n",
    "\n",
    "np.random.seed(random_seed)\n",
    "\n",
    "# transforms에서 random 라이브러리를 사용하기 때문에 random 라이브러리를 불러서 고정\n",
    "\n",
    "random.seed(random_seed)\n",
    "\n",
    "# GPU 에서 사용하는 난수 생성 시드 고정\n",
    "\n",
    "torch.cuda.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e8128f-cb16-481a-bd8b-d851858c1f67",
   "metadata": {},
   "source": [
    "## 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c34b99-7895-47d1-966b-3f5da02672e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이상치 이미지 시각화\n",
    "def show_img(img_id_li, df, data_dir):\n",
    "    for img_id in img_id_li:\n",
    "        get_df = df[df['id'] == img_id]\n",
    "        \n",
    "        img_age = get_df['age'].tolist()[0]\n",
    "        img_gender = get_df['gender'].tolist()[0]\n",
    "        \n",
    "        img_path = get_df['path'].tolist()[0]\n",
    "        img_path = os.path.join(data_dir, img_path)\n",
    "        img_name_li = sorted(list(os.listdir(img_path)))\n",
    "        \n",
    "        fig, ax = plt.subplots(1, 7, figsize = (30, 15))\n",
    "        ax = ax.flatten()\n",
    "        \n",
    "        idx = 0\n",
    "        for _img_name in img_name_li:\n",
    "            if _img_name[0] == '.': continue\n",
    "            \n",
    "            if _img_name.split('.')[0] == 'normal': imag_name = 'normal'\n",
    "            elif _img_name.split('.')[0] == 'incorrect_mask': imag_name = 'incorrect_mask'\n",
    "            else: imag_name = 'mask'\n",
    "            \n",
    "            get_img_path = os.path.join(img_path, _img_name)\n",
    "            \n",
    "            img = Image.open(get_img_path)\n",
    "            img = np.array(img)\n",
    "            ax[idx].imshow(img)\n",
    "            ax[idx].set_title(f'{img_id} / {img_age} / {img_gender} / {imag_name}')\n",
    "            ax[idx].set_xticks([])\n",
    "            ax[idx].set_yticks([])\n",
    "            idx += 1\n",
    "            \n",
    "        plt.show()\n",
    "\n",
    "# image path로 이미지 시각화\n",
    "def path_li_show_img(path_li):\n",
    "    fig, ax = plt.subplots(1, 7, figsize = (30, 15))\n",
    "    ax = ax.flatten()\n",
    "    idx = 0\n",
    "    for path in path_li:\n",
    "        image_name = path.split('/')[-1]\n",
    "        img = Image.open(path)\n",
    "        img = np.array(img)\n",
    "        ax[idx].imshow(img)\n",
    "        ax[idx].set_title(f'{image_name}')\n",
    "        ax[idx].set_xticks([])\n",
    "        ax[idx].set_yticks([])\n",
    "        idx += 1\n",
    "    plt.show()\n",
    "\n",
    "# ages 생성\n",
    "def get_ages(x):\n",
    "    if x < 30: return 0\n",
    "    elif x < 60: return 1\n",
    "    else: return 2\n",
    "\n",
    "# genders 생성\n",
    "def get_genders(x):\n",
    "    if x == 'male': return 0\n",
    "    else: return 1\n",
    "\n",
    "# masks 생성\n",
    "def get_masks(x):\n",
    "    if x == 'normal': return 2\n",
    "    elif x == 'incorrect_mask': return 1\n",
    "    else: return 0\n",
    "\n",
    "# labels 생성\n",
    "def get_labels(masks, genders, ages):\n",
    "    return masks * 6 + genders * 3 + ages\n",
    "\n",
    "# train_df 생성\n",
    "def get_train_df(df):\n",
    "    train_df = []\n",
    "    train_data_dir = '../input/data/train/'\n",
    "    for line in df.iloc:\n",
    "        for file in list(os.listdir(os.path.join(train_image_dir, line['path']))):\n",
    "            if file[0] == '.':\n",
    "                continue\n",
    "                \n",
    "            mask = file.split('.')[0]\n",
    "            gender = line['gender']\n",
    "            age = line['age']\n",
    "            \n",
    "            masks = get_masks(mask)\n",
    "            genders = get_genders(gender)\n",
    "            ages = get_ages(age)\n",
    "            \n",
    "            data = {\n",
    "                'id' : line['id'],\n",
    "                'mask' : mask,\n",
    "                'gender' : gender,\n",
    "                'age' : age,\n",
    "                'masks' : masks,\n",
    "                'genders' : genders,\n",
    "                'ages' : ages,\n",
    "                'cv_target_col' : line['cv_target_col'],\n",
    "                'labels': get_labels(masks = masks, genders = genders, ages = ages),\n",
    "                'path': os.path.join(train_image_dir, line['path'], file),\n",
    "            }\n",
    "            train_df.append(data)\n",
    "            \n",
    "    train_df = pd.DataFrame(train_df)\n",
    "    train_df['idx'] = train_df.index\n",
    "    train_df['transform'] = 0\n",
    "    \n",
    "    return train_df\n",
    "\n",
    "# 성별 이상치 처리\n",
    "def swap_gender(swap_li, df):\n",
    "    swap_df = df.copy()\n",
    "    for swap in swap_li:\n",
    "        swap_id, swap_gender = swap\n",
    "        swap_df.loc[swap_df[swap_df['id'] == swap_id].index, 'gender'] = swap_gender\n",
    "    return swap_df\n",
    "        \n",
    "# 전처리된 df 생성 - 성별 결측치 처리, cv_target_col 생성\n",
    "def preprocessing_df(df, swap_gender_li):\n",
    "    '''\n",
    "    swap_gender_li = [['006359', 'male'], ['006360', 'male'], ['006361', 'male'], ['006362', 'male'], ['006363', 'male'], ['006364', 'male']]\n",
    "    '''\n",
    "    \n",
    "    preprocessing_df = df.copy()\n",
    "    preprocessing_df = swap_gender(swap_li = swap_gender_li, df = preprocessing_df)\n",
    "    \n",
    "    preprocessing_df['ages'] = preprocessing_df['age'].apply(lambda x : get_ages(x))\n",
    "    preprocessing_df['genders'] = preprocessing_df['gender'].apply(lambda x : get_genders(x))\n",
    "    \n",
    "    preprocessing_df['cv_target_col'] = 'ages' + '_' + preprocessing_df['ages'].astype(str) + '_' + 'genders' + '_' + preprocessing_df['genders'].astype(str)\n",
    "    \n",
    "    return preprocessing_df\n",
    "\n",
    "# val_idx 생성\n",
    "def get_val_idx(df, target_col):\n",
    "    skf = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 22)\n",
    "    for trn_idx, val_idx in skf.split(df, df[target_col]):\n",
    "        yield val_idx\n",
    "\n",
    "# 마스크 이상치 변경\n",
    "def swap_mask(swap_li, df):\n",
    "    swap_df = df.copy()\n",
    "    for swap_id in swap_li:\n",
    "        _swap_df = swap_df[swap_df['id'] == swap_id]\n",
    "        \n",
    "        normal_swap_df = _swap_df[_swap_df['mask'] == 'normal']\n",
    "        incorrect_mask_swap_df = _swap_df[_swap_df['mask'] == 'incorrect_mask']\n",
    "        \n",
    "        normal_path = normal_swap_df['path'].values[0]\n",
    "        incorrect_mask_path = incorrect_mask_swap_df['path'].values[0]\n",
    "        \n",
    "        swap_df.loc[normal_swap_df.index, 'path'] = incorrect_mask_path\n",
    "        swap_df.loc[incorrect_mask_swap_df.index, 'path'] = normal_path\n",
    "    \n",
    "    return swap_df\n",
    "\n",
    "def id_split(df):\n",
    "    temp_df = df.copy()\n",
    "\n",
    "    train_idx, val_idx = train_test_split(temp_df['cv_target_col'], train_size = 0.8, random_state = 42, stratify = temp_df['cv_target_col'])\n",
    "                                      \n",
    "    train_id, val_id = temp_df.loc[train_idx.index, 'id'], temp_df.loc[val_idx.index, 'id']\n",
    "    \n",
    "    return train_id, val_id\n",
    "\n",
    "def df_split(df, train_id, val_id):\n",
    "    temp_df = df.copy()\n",
    "    \n",
    "    train_set = temp_df[temp_df['id'].isin(train_id.unique())]\n",
    "    val_set = temp_df[temp_df['id'].isin(val_id.unique())]\n",
    "    \n",
    "    train_set.drop(columns=['idx'], inplace = True)\n",
    "    val_set.drop(columns=['idx'], inplace = True)\n",
    "    \n",
    "    return train_set, val_set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e15b86b-4223-43e6-94c8-4d19ae234700",
   "metadata": {},
   "source": [
    "### 오버 샘플링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b402d4-95b8-4629-915d-c8430042264f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## train_set transform setting\n",
    "\n",
    "def transform_setting(train_df, sampling_list, transform_count):\n",
    "    df = train_df.copy()\n",
    "\n",
    "    \n",
    "    unsampling_df = df[~df['labels'].isin(sampling_list)]\n",
    "    unsampling_df.reset_index(drop = True, inplace = True)\n",
    "    \n",
    "    row_size = len(unsampling_df)\n",
    "    \n",
    "    unsampling_df['transform'] = pd.DataFrame(np.random.randint(0, transform_count, size=(row_size, 1)), columns=['transform'], dtype=np.int64)\n",
    "       \n",
    "    return unsampling_df\n",
    "\n",
    "## 오버 샘플링\n",
    "\n",
    "def over_sampling(train_df, sampling_list, transform_count):\n",
    "    df = train_df.copy()\n",
    "    \n",
    "    temp_df = df[df['labels'].isin(sampling_list)] \n",
    "    \n",
    "    sampling_df = pd.DataFrame()\n",
    "    \n",
    "    for transform_idx in range(transform_count):\n",
    "        temp_df['transform'] = transform_idx\n",
    "        sampling_df = pd.concat([sampling_df, temp_df], ignore_index=True)\n",
    "    \n",
    "    sampling_df.reset_index(drop = True, inplace = True)\n",
    "    \n",
    "    return sampling_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c25f72a-1358-4f70-a8cf-41fbfc63675a",
   "metadata": {},
   "source": [
    "## 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd17fab-28a1-43c0-bda0-0e4572ef6e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(data_dir + 'train.csv')\n",
    "submission = pd.read_csv(test_dir + 'info.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bece0af8-cd0f-438e-a87e-91b1b975f4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "신규범님 코드 참고\n",
    "\n",
    "학습 데이터 구축\n",
    "'''\n",
    "image_size = (512, 384)\n",
    "image_normal_mean = (0.485, 0.456, 0.406)\n",
    "image_normal_std = (0.229, 0.224, 0.225)\n",
    "crop_size = 384\n",
    "blur_kernel_size = 19\n",
    "brightness = 0.8\n",
    "rotation = 10\n",
    "\n",
    "# 적용할 transform 목록 정의\n",
    "transform_list = [\n",
    "    transforms.Compose([\n",
    "#     Resize(image_size, Image.BILINEAR),\n",
    "    ToTensor(),\n",
    "    transforms.CenterCrop(crop_size),\n",
    "    Normalize(mean=image_normal_mean, std=image_normal_std),\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "]),\n",
    "    \n",
    "    transforms.Compose([\n",
    "    transforms.GaussianBlur(blur_kernel_size),\n",
    "]),\n",
    "        \n",
    "    transforms.Compose([\n",
    "    transforms.ColorJitter(brightness = brightness),\n",
    "]),\n",
    "    \n",
    "    transforms.Compose([\n",
    "    transforms.RandomRotation(rotation),\n",
    "]),\n",
    "             \n",
    "]\n",
    "\n",
    "# 성별 라벨링, 마스크 라벨링 변환할 사람 정의\n",
    "swap_gender_li = [['006359', 'male'], ['006360', 'male'], ['006361', 'male'], ['006362', 'male'], ['006363', 'male'], ['006364', 'male'],\n",
    "                 ['001498-1', 'female'], ['004432', 'female']]\n",
    "swap_mask_li = ['000020', '004418', '005227']\n",
    "\n",
    "# 오버샘플링 진행할 label\n",
    "sampling_list = [2, 5, 8, 11, 14, 17]\n",
    "\n",
    "# transform 개수\n",
    "transform_count = len(transform_list)\n",
    "\n",
    "pre_df = preprocessing_df(df = train_df, swap_gender_li = swap_gender_li)\n",
    "\n",
    "train_id, val_id = id_split(pre_df)\n",
    "\n",
    "train_set = get_train_df(df = pre_df)\n",
    "\n",
    "train_set = swap_mask(swap_li = swap_mask_li, df = train_set)\n",
    "\n",
    "train_set, val_set = df_split(train_set, train_id, val_id) \n",
    "\n",
    "unsampling_set = transform_setting(train_set, sampling_list, transform_count)\n",
    "\n",
    "sampling_set = over_sampling(train_set, sampling_list, transform_count)\n",
    "\n",
    "train_set = pd.concat([unsampling_set, sampling_set], ignore_index=True)\n",
    "\n",
    "train_set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3f4bf2-13a5-42ac-a693-2d43d91186bd",
   "metadata": {},
   "source": [
    "## 데이터셋 구축"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fcd8690-6d91-4e99-8984-3872dc266bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Sample_submission 코드 참고\n",
    "\n",
    "데이터 셋 구축\n",
    "'''\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, df, transform_list, train = True):\n",
    "        self.train = train\n",
    "        self.df = df\n",
    "        if self.train:\n",
    "            self.img_paths = self.df['path'].tolist()\n",
    "            self.targets = self.df['labels'].tolist()\n",
    "            self.transform_idx = self.df['transform'].tolist()\n",
    "        else:\n",
    "            self.img_paths = [os.path.join(submission_image_dir, img_id) for img_id in self.df.ImageID]\n",
    "        self.transform = transform_list\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = Image.open(self.img_paths[index])\n",
    "        \n",
    "        \n",
    "        # 이 부분에 해당 라벨에 따른 데이터 변환 여부 추가\n",
    "        # val 데이터의 경우 데이터 변환이 일어나면 안되기 때문에\n",
    "        # if self.데이터 변환해주는 transform:\n",
    "        #     if self.targets[index].data == labels: <- 확률적으로\n",
    "        #          image = self.데이터 변환해주는 transform(image)\n",
    "        # 데이터 변환\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform[0](image)\n",
    "        \n",
    "        if self.train:\n",
    "            if self.transform_idx[index] != 0:\n",
    "                image = self.transform[self.transform_idx[index]](image)\n",
    "                \n",
    "            targets = torch.tensor(self.targets[index])\n",
    "            return image, targets\n",
    "        \n",
    "        else: return image\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd23ff4-e95a-4227-aa8d-e8abfd8089f4",
   "metadata": {},
   "source": [
    "## 학습 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4900c6-4f60-42f9-9b17-600560163d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "학습 함수 설정\n",
    "'''\n",
    "\n",
    "def train(model, data_loader, optimizer, scheduler, criterion):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    f1 = 0\n",
    "    \n",
    "    for batch_idx, (images, targets) in enumerate(data_loader):\n",
    "        images, targets = images.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        benign_outputs = model(images)\n",
    "        loss = criterion(benign_outputs, targets)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = benign_outputs.max(1)\n",
    "\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "        f1 += f1_score(targets.cpu().tolist(), predicted.cpu().tolist(), average='macro')\n",
    "        \n",
    "    train_loss /= len(data_loader)\n",
    "    acc = correct / total\n",
    "    f1 /= len(data_loader)\n",
    "    \n",
    "    scheduler.step(train_loss)\n",
    "    \n",
    "    return train_loss, acc, f1\n",
    "\n",
    "\n",
    "def val(model, data_loader, criterion):\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    f1 = 0\n",
    "    \n",
    "    for batch_idx, (images, targets) in enumerate(data_loader):\n",
    "        with torch.no_grad():\n",
    "            images, targets = images.to(device), targets.to(device)\n",
    "            benign_outputs = model(images)\n",
    "            loss = criterion(benign_outputs, targets)\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = benign_outputs.max(1)\n",
    "\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "            f1 += f1_score(targets.cpu().tolist(), predicted.cpu().tolist(), average='macro')\n",
    "    \n",
    "    val_loss /= len(data_loader)\n",
    "    acc = correct / total\n",
    "    f1 /= len(data_loader)\n",
    "    \n",
    "    return val_loss, acc, f1\n",
    "\n",
    "def pred(model, data_loader):\n",
    "    model.eval()\n",
    "    all_predictions = []\n",
    "    for images in data_loader:\n",
    "        with torch.no_grad():\n",
    "            images = images.to(device)\n",
    "            pred = model(images)\n",
    "            pred = pred.argmax(dim=-1)\n",
    "            all_predictions.extend(pred.cpu().numpy())\n",
    "            \n",
    "    return all_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386d18c3-8ba8-4245-8745-8bf43f3b69b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "학습 설정\n",
    "'''\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "lr = 0.001\n",
    "epochs = 30\n",
    "batch_size = 128\n",
    "num_workers = 3\n",
    "class_nums = 18"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e5b68e-746b-484e-bafd-34948e250d15",
   "metadata": {},
   "source": [
    "## 데이터 로더 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eebb7b9-d491-4503-ad05-6026e3baacf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "데이터 로더 생성\n",
    "'''\n",
    "\n",
    "\n",
    "train_customset = CustomDataset(df = train_set, transform_list = transform_list, train = True)\n",
    "val_customset = CustomDataset(df = val_set, transform_list = transform_list, train = True)\n",
    "test_customset = CustomDataset(df = submission, transform_list = transform_list, train = False)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_customset,\n",
    "    batch_size = batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers = num_workers,\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_customset,\n",
    "    batch_size = batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers = num_workers,\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_customset,\n",
    "    batch_size = batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers = num_workers,\n",
    ")\n",
    "\n",
    "# 사람 다르게 하는 col\n",
    "cv_taget_col = 'cv_taget_col'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b147b7-b5b8-4570-bc70-3c76925ff1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "모델 설정\n",
    "'''\n",
    "model = models.regnet_y_400mf(pretrained=True).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor = 0.1, eps = 1e-09, patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da605dd-8652-4fcd-b91e-7c207393a644",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48452261-dba3-497e-b963-53bb3743f8fe",
   "metadata": {},
   "source": [
    "## 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516e7a82-9341-4e90-8f04-dbd8340329f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_features = model.fc.in_features\n",
    "model.fc = torch.nn.Linear(in_features=in_features, out_features=class_nums, bias=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9471476-b22c-44a0-b381-c18e275d2ae9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "min_val_loss = float(\"inf\")\n",
    "early_stopping_count = 0\n",
    "\n",
    "for epoch in tqdm(range(1, epochs + 1)):\n",
    "    train_loss, train_acc, train_f1 = train(model = model, data_loader = train_loader, optimizer = optimizer, scheduler = scheduler, criterion = criterion)\n",
    "    val_loss, val_acc, val_f1 = val(model = model, data_loader = val_loader, criterion = criterion)\n",
    "    \n",
    "    print(f'epoch : {epoch}, train_loss : {train_loss}, train_acc : {train_acc}, train_f1 : {train_f1}, val_loss : {val_loss}, val_acc : {val_acc}, val_f1 : {val_f1}')\n",
    "    \n",
    "    # 모델 저장\n",
    "    if val_loss < min_val_loss:\n",
    "        min_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), model_dir + f'best_regnet_y_400mf_upsampling.pt')\n",
    "        early_stopping_count = 0\n",
    "    else:\n",
    "        early_stopping_count += 1\n",
    "        if early_stopping_count == 10:\n",
    "            print('early_stopping')\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aee7b39-b5bb-4df9-a4c1-03723c0189e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.regnet_y_400mf(pretrained=False).to(device)\n",
    "in_features = model.fc.in_features\n",
    "model.fc = torch.nn.Linear(in_features=in_features, out_features=class_nums, bias=True).to(device)\n",
    "model.load_state_dict(torch.load(model_dir + f'best_regnet_y_400mf_upsampling.pt', map_location = device))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c59ac7-00f9-4d76-949e-08d27c65c5fa",
   "metadata": {},
   "source": [
    "## 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283014b4-8e99-4e47-8d3f-c1797c03128f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델이 테스트 데이터셋을 예측하고 결과를 저장합니다.\n",
    "all_predictions = pred(model = model, data_loader = test_loader)\n",
    "submission['ans'] = all_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bcbca1b-c238-4f10-bb42-7ba36fe25de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_f1_score(y_true, y_pred):\n",
    "    return f1_score(y_true, y_pred, average='macro')\n",
    "\n",
    "def get_acc_score(y_true, y_pred):\n",
    "    return accuracy_score(y_true, y_pred)\n",
    "\n",
    "\n",
    "def val_pred(model, data_loader):\n",
    "    model.eval()\n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "    for (images, targets) in data_loader:\n",
    "        with torch.no_grad():\n",
    "            images, targets = images.to(device), targets.to(device)\n",
    "            pred = model(images)\n",
    "            pred = pred.argmax(dim=-1)\n",
    "            all_predictions.extend(pred.cpu().numpy())\n",
    "            all_targets.extend(targets.cpu().numpy())\n",
    "            \n",
    "    return all_predictions, all_targets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4196b7-7f40-436d-9877-df13109b8bdf",
   "metadata": {},
   "source": [
    "## confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c14c540-0708-4193-bb26-c5e03d2f4b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_predictions, val_targets = val_pred(model = model, data_loader = val_loader)\n",
    "\n",
    "val_f1 = get_f1_score(y_true = val_targets, y_pred = val_predictions)\n",
    "val_acc = get_acc_score(y_true = val_targets, y_pred = val_predictions)\n",
    "\n",
    "val_confusion_matrix = pd.DataFrame((confusion_matrix(y_true = val_targets, y_pred = val_predictions)))\n",
    "print(f'val confusion_matrix')\n",
    "display(val_confusion_matrix.style.background_gradient(cmap='YlOrRd', axis = 0))\n",
    "print(f'val fi : {val_f1}, val acc: {val_acc} \\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e8c2ad-0bd3-4421-8c07-c06d819238a3",
   "metadata": {},
   "source": [
    "## 제출 파일 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3df5b40-9141-4641-9c20-6ec9623d5544",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제출할 파일을 저장합니다.\n",
    "submission.to_csv(os.path.join(submission_dir, 'regnet_y_400mf_upsampling.csv'), index=False)\n",
    "print('test inference is done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f218c845-7bb3-4334-9eaf-b3b4c13252c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04233024-211c-4869-9d25-ea2c6b01ffab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
