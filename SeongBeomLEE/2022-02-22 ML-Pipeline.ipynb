{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5bf2f31-871a-4692-8715-6dfd9e2e5571",
   "metadata": {},
   "source": [
    "# 패키지 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57ef633d-5fc3-46bc-b25e-0f618defbe59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import Resize, ToTensor, Normalize\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6649898a-c4c2-4432-a8de-bb62dc574bbb",
   "metadata": {},
   "source": [
    "# 학습 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02929318-060c-48b8-8706-c513499d0751",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "학습 설정\n",
    "\n",
    "추후에 argparser로 설정하면 될 듯\n",
    "\n",
    "'''\n",
    "\n",
    "train_data_dir = '../input/data/train/'\n",
    "submission_data_dir = '../input/data/eval/'\n",
    "\n",
    "train_image_dir = '../input/data/train/images'\n",
    "submission_image_dir = '../input/data/eval/images'\n",
    "\n",
    "model_dir = '../model/'\n",
    "\n",
    "test_size = 0.2\n",
    "fold_num = 5\n",
    "seed = 22\n",
    "\n",
    "lr = 0.005\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "batch_size = 128\n",
    "epochs = 10\n",
    "\n",
    "image_size = (128, 128)\n",
    "image_normal_mean = (0.5, 0.5, 0.5)\n",
    "image_normal_std = (0.2, 0.2, 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242f7a6e-de2f-48c0-9c58-194a2f02c663",
   "metadata": {},
   "source": [
    "# 데이터 로드 및 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ff8ff3a-42ab-479e-adfe-1d60d6be5c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(train_data_dir + 'train.csv')\n",
    "submission = pd.read_csv(submission_data_dir + 'info.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78f17d3b-ffb2-4a1e-955e-f4c67125b107",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>race</th>\n",
       "      <th>age</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2399</th>\n",
       "      <td>006359</td>\n",
       "      <td>male</td>\n",
       "      <td>Asian</td>\n",
       "      <td>18</td>\n",
       "      <td>006359_female_Asian_18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id gender   race  age                    path\n",
       "2399  006359   male  Asian   18  006359_female_Asian_18"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "이상치 처리\n",
    "\n",
    "'''\n",
    "\n",
    "df.loc[df[df['id'] == '006359'].index, 'gender'] = 'male'\n",
    "df.loc[df[df['id'] == '006359'].index, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0b0f7f6-2284-458e-9f45-5516421674ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2700it [00:00, 2772.54it/s]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "학습 데이터셋 구축\n",
    "\n",
    "'''\n",
    "def get_age_group(x):\n",
    "    if x < 30: return 0\n",
    "    elif x < 60: return 1\n",
    "    else: return 2\n",
    "\n",
    "def get_gender_group(x):\n",
    "    if x == 'male': return 0\n",
    "    else: return 1\n",
    "\n",
    "def get_train_df(df):\n",
    "    train_df = []\n",
    "\n",
    "    for idx, line in enumerate(tqdm(df.iloc)):\n",
    "        for file in list(os.listdir(os.path.join(train_image_dir, line['path']))):\n",
    "            if file[0] == '.':\n",
    "                continue\n",
    "            if file.split('.')[0] == 'normal':\n",
    "                mask = 2\n",
    "            elif file.split('.')[0] == 'incorrect_mask':\n",
    "                mask = 1\n",
    "            else:\n",
    "                mask = 0\n",
    "                \n",
    "            mask_state = file.split('.')[0]\n",
    "            gender_group = get_gender_group(line['gender'])\n",
    "            age_group = get_age_group(line['age'])\n",
    "            \n",
    "            data = {\n",
    "                'id' : line['id'],\n",
    "                'gender' : line['gender'],\n",
    "                'gender_group' : gender_group,\n",
    "                'age' : line['age'],\n",
    "                'age_group' : age_group,\n",
    "                'mask_state': mask_state,\n",
    "                'mask' : mask,\n",
    "                'path': os.path.join(train_image_dir, line['path'], file),\n",
    "                'label': mask * 6 + gender_group * 3 + age_group\n",
    "            }\n",
    "            \n",
    "            train_df.append(data)\n",
    "            \n",
    "    train_df = pd.DataFrame(train_df)\n",
    "    \n",
    "    return train_df\n",
    "\n",
    "train_df = get_train_df(df = df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9479acf6-247b-4a5c-98d2-e96ed45e6dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "데이터셋 분리\n",
    "\n",
    "'''\n",
    "\n",
    "train_idx, test_idx = train_test_split(train_df['label'], train_size = 1 - test_size, random_state = seed, stratify = train_df['label'])\n",
    "                                      \n",
    "train_set, test_set = train_df.iloc[train_idx.index, :].reset_index(drop = True), train_df.iloc[test_idx.index, :].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f78cb0f-fc86-4c93-a1d3-fb8b43d6fdaf",
   "metadata": {},
   "source": [
    "# 모델 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6f656f7-1bb2-4e74-9d97-ad91cf4dd212",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "ResNet 모델 구축\n",
    "\n",
    "나동빈님 코드 참고\n",
    "\n",
    "https://github.com/ndb796/Deep-Learning-Paper-Review-and-Practice/blob/master/code_practices/ResNet18_MNIST_Train.ipynb\n",
    "\n",
    "'''\n",
    "\n",
    "# ResNet18을 위해 최대한 간단히 수정한 BasicBlock 클래스 정의\n",
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "\n",
    "        # 3x3 필터를 사용 (너비와 높이를 줄일 때는 stride 값 조절)\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes) # 배치 정규화(batch normalization)\n",
    "\n",
    "        # 3x3 필터를 사용 (패딩을 1만큼 주기 때문에 너비와 높이가 동일)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes) # 배치 정규화(batch normalization)\n",
    "\n",
    "        self.shortcut = nn.Sequential() # identity인 경우\n",
    "        if stride != 1: # stride가 1이 아니라면, Identity mapping이 아닌 경우\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x) # (핵심) skip connection\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "# ResNet 클래스 정의\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 64\n",
    "\n",
    "        # 64개의 3x3 필터(filter)를 사용\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        self.linear = nn.Linear(512, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1] * (num_blocks - 1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes # 다음 레이어를 위해 채널 수 변경\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 16)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5abea89-1af7-47f1-902b-979a8c51d81c",
   "metadata": {},
   "source": [
    "# 데이터셋 구축"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b2bfade-30ab-4554-acf1-9826b2230594",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "Sample_submission 코드 참고\n",
    "\n",
    "증강 데이터 생성은 본 함수에 추가할 것\n",
    "\n",
    "데이터 셋 구축\n",
    "\n",
    "'''\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, df, transform, train = True):\n",
    "        self.train = train\n",
    "        self.df = df\n",
    "        if self.train:\n",
    "            self.img_paths = self.df['path'].tolist()\n",
    "            self.genders = self.df['gender_group'].tolist()\n",
    "            self.ages = self.df['age_group'].tolist()\n",
    "            self.masks = self.df['mask'].tolist()\n",
    "            self.labels = self.df['label'].tolist()\n",
    "        else:\n",
    "            self.img_paths = [os.path.join(submission_image_dir, img_id) for img_id in self.df.ImageID]\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = Image.open(self.img_paths[index])\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        if self.train:\n",
    "            label = torch.tensor(self.labels[index])\n",
    "            age = torch.tensor(self.ages[index])\n",
    "            gender = torch.tensor(self.genders[index])\n",
    "            mask = torch.tensor(self.masks[index])\n",
    "            return image, label, age, gender, mask\n",
    "        \n",
    "        else: return image\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae21fe3-2800-4004-baff-03d3513532e8",
   "metadata": {},
   "source": [
    "# 학습 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8a15f92-6c38-42af-b472-16d58a73df1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_f1_score(y_true, y_pred):\n",
    "    return f1_score(y_true, y_pred, average='macro')\n",
    "\n",
    "def model_train(model, optimizer, criterion, images, targets):\n",
    "    model.train()\n",
    "    \n",
    "    images, targets = images.to(device), targets.to(device)\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    benign_outputs = model(images)\n",
    "    loss = criterion(benign_outputs, targets)\n",
    "    loss.backward()\n",
    "    \n",
    "    optimizer.step()\n",
    "    \n",
    "    train_loss = loss.item()\n",
    "    _, predicted = benign_outputs.max(1)\n",
    "    \n",
    "    correct = predicted.eq(targets).sum().item()\n",
    "    \n",
    "    fl_socre = get_f1_score(y_true = targets.cpu().tolist(), y_pred = predicted.cpu().tolist())\n",
    "    \n",
    "    return train_loss, correct, fl_socre\n",
    "\n",
    "def batch_train(model, optimizer, criterion, images, targets, train_loss, train_acc, train_fi_score):\n",
    "    loss, acc, fi_score = model_train(model = model, optimizer = optimizer, criterion = criterion, images = images, targets = targets)\n",
    "    train_loss += loss\n",
    "    train_acc += acc\n",
    "    train_fi_score += fi_score\n",
    "\n",
    "    return train_loss, train_acc, train_fi_score\n",
    "\n",
    "\n",
    "def model_eval(model, criterion, images, targets):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        images, targets = images.to(device), targets.to(device)\n",
    "        benign_outputs = model(images)\n",
    "        loss = criterion(benign_outputs, targets)\n",
    "        \n",
    "        val_loss = loss.item()\n",
    "        _, predicted = benign_outputs.max(1)\n",
    "        \n",
    "        correct = predicted.eq(targets).sum().item()\n",
    "        fl_socre = get_f1_score(y_true = targets.cpu().tolist(), y_pred = predicted.cpu().tolist())\n",
    "   \n",
    "    return val_loss, correct, fl_socre\n",
    "\n",
    "def batch_eval(model, criterion, images, targets, val_loss, val_acc, val_fi_score):\n",
    "    loss, acc, fi_score = model_eval(model = model, criterion = criterion, images = images, targets = targets)\n",
    "    val_loss += loss\n",
    "    val_acc += acc\n",
    "    val_fi_score += fi_score\n",
    "\n",
    "    return val_loss, val_acc, val_fi_score\n",
    "\n",
    "def ensemble(model, images):\n",
    "    model.eval()\n",
    "    all_predictions = []\n",
    "    with torch.no_grad():\n",
    "        images = images.to(device)\n",
    "        pred = model(images)\n",
    "        pred = pred.softmax(dim = 1)\n",
    "        all_predictions.extend(pred.cpu().numpy())\n",
    "    \n",
    "    return all_predictions\n",
    "\n",
    "def get_loss(loss, acc, fi_score, data_loder, total):\n",
    "    loss /= len(data_loder)\n",
    "    acc /= total\n",
    "    fi_score /= len(data_loder)\n",
    "\n",
    "    return loss, acc, fi_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8cccaa0-0a7f-4462-be63-d6c3d7cd1ed7",
   "metadata": {},
   "source": [
    "# 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54615321-aadf-4592-b42c-db9bde6d180f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "데이터 전처리 함수\n",
    "\n",
    "데이터 증강 등의 함수를 수정해서 사용하면 될 듯 함\n",
    "\n",
    "'''\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    Resize(image_size, Image.BILINEAR),\n",
    "    ToTensor(),\n",
    "    Normalize(mean=image_normal_mean, std=image_normal_std),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a45592-8a1e-4377-80a3-372c2e13bab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "학습 시작\n",
    "\n",
    "'''\n",
    "total_start_time = time.time()\n",
    "\n",
    "skf = StratifiedKFold(n_splits = fold_num, random_state = seed, shuffle = True)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "for now_fold_num, (trn_idx, val_idx) in enumerate(skf.split(train_set, train_set['label'])):\n",
    "    fold_start_time = time.time()\n",
    "    \n",
    "    # 데이터 정의\n",
    "    trn_df = train_set.iloc[trn_idx, :]\n",
    "    val_df = train_set.iloc[val_idx, :]\n",
    "    \n",
    "    trn_dataset = CustomDataset(df = trn_df, \n",
    "                                transform = transform, \n",
    "                                train = True)\n",
    "    \n",
    "    val_dataset = CustomDataset(df = val_df, \n",
    "                                transform = transform, \n",
    "                                train = True)\n",
    "    \n",
    "    train_loder = DataLoader(\n",
    "    trn_dataset,\n",
    "    batch_size = batch_size,\n",
    "    shuffle=True,\n",
    "    )\n",
    "    \n",
    "    val_loder = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size = batch_size,\n",
    "    shuffle = False,\n",
    "    )\n",
    "    \n",
    "    # 모델 정의\n",
    "    label_model = ResNet(block = BasicBlock, \n",
    "                         num_blocks = [2, 2, 2, 2],\n",
    "                         num_classes = 18).to(device)\n",
    "    \n",
    "    mask_model = ResNet(block = BasicBlock, \n",
    "                        num_blocks = [2, 2, 2, 2], \n",
    "                        num_classes = 3).to(device)\n",
    "    \n",
    "    gender_model = ResNet(block = BasicBlock, \n",
    "                          num_blocks = [2, 2, 2, 2], \n",
    "                          num_classes = 2).to(device)\n",
    "    \n",
    "    age_model = ResNet(block = BasicBlock, \n",
    "                       num_blocks = [2, 2, 2, 2], \n",
    "                       num_classes = 3).to(device)\n",
    "    \n",
    "    # optimizer 설정\n",
    "    label_optimizer = optim.Adam(label_model.parameters(), lr=lr)\n",
    "    mask_optimizer = optim.Adam(mask_model.parameters(), lr=lr)\n",
    "    gender_optimizer = optim.Adam(gender_model.parameters(), lr=lr)\n",
    "    age_optimizer = optim.Adam(age_model.parameters(), lr=lr)\n",
    "    \n",
    "    # scheduler 설정\n",
    "    label_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(label_optimizer, 'min', factor = 0.1, eps = 1e-09, patience = 5)\n",
    "    mask_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(mask_optimizer, 'min', factor = 0.1, eps = 1e-09, patience = 5)\n",
    "    gender_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(gender_optimizer, 'min', factor = 0.1, eps = 1e-09, patience = 5)\n",
    "    age_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(age_optimizer, 'min', factor = 0.1, eps = 1e-09, patience = 5)\n",
    "    \n",
    "    # besf_metric 설정\n",
    "    label_besf_fi = 0\n",
    "    mask_besf_fi = 0\n",
    "    gender_besf_fi = 0\n",
    "    age_besf_fi = 0\n",
    "    \n",
    "    for epoch in range(1, epochs + 1):\n",
    "        epoch_start_time = time.time()\n",
    "        \n",
    "        # 메트릭 정의\n",
    "        total = 0\n",
    "        train_label_loss, train_label_acc, train_label_fi_score, val_label_loss, val_label_acc, val_label_fi_score = 0, 0, 0, 0, 0, 0\n",
    "        train_mask_loss, train_mask_acc, train_mask_fi_score, val_mask_loss, val_mask_acc, val_mask_fi_score = 0, 0, 0, 0, 0, 0\n",
    "        train_gender_loss, train_gender_acc, train_gender_fi_score, val_gender_loss, val_gender_acc, val_gender_fi_score = 0, 0, 0, 0, 0, 0\n",
    "        train_age_loss, train_age_acc, train_age_fi_score, val_age_loss, val_age_acc, val_age_fi_score = 0, 0, 0, 0, 0, 0\n",
    "        \n",
    "        # 학습\n",
    "        for images, labels, ages, genders, masks in train_loder:\n",
    "            total += labels.size(0)\n",
    "            \n",
    "            train_label_loss, train_label_acc, train_label_fi_score = batch_train(model = label_model, \n",
    "                                                                                   optimizer = label_optimizer, \n",
    "                                                                                   criterion = criterion, \n",
    "                                                                                   images = images, \n",
    "                                                                                   targets = labels, \n",
    "                                                                                   train_loss = train_label_loss, \n",
    "                                                                                   train_acc = train_label_acc, \n",
    "                                                                                   train_fi_score = train_label_fi_score)\n",
    "            \n",
    "            train_mask_loss, train_mask_acc, train_mask_fi_score = batch_train(model = mask_model, \n",
    "                                                                                   optimizer = mask_optimizer, \n",
    "                                                                                   criterion = criterion, \n",
    "                                                                                   images = images, \n",
    "                                                                                   targets = masks, \n",
    "                                                                                   train_loss = train_mask_loss, \n",
    "                                                                                   train_acc = train_mask_acc, \n",
    "                                                                                   train_fi_score = train_mask_fi_score)\n",
    "            \n",
    "            train_gender_loss, train_gender_acc, train_gender_fi_score = batch_train(model = gender_model, \n",
    "                                                                                   optimizer = gender_optimizer, \n",
    "                                                                                   criterion = criterion, \n",
    "                                                                                   images = images, \n",
    "                                                                                   targets = genders, \n",
    "                                                                                   train_loss = train_gender_loss, \n",
    "                                                                                   train_acc = train_gender_acc, \n",
    "                                                                                   train_fi_score = train_gender_fi_score)\n",
    "            \n",
    "            \n",
    "            train_age_loss, train_age_acc, train_age_fi_score = batch_train(model = age_model, \n",
    "                                                                                   optimizer = age_optimizer, \n",
    "                                                                                   criterion = criterion, \n",
    "                                                                                   images = images, \n",
    "                                                                                   targets = ages, \n",
    "                                                                                   train_loss = train_age_loss, \n",
    "                                                                                   train_acc = train_age_acc, \n",
    "                                                                                   train_fi_score = train_age_fi_score)\n",
    "            \n",
    "        \n",
    "        # total_loss 계산\n",
    "        train_label_loss, train_label_acc, train_label_fi_score = get_loss(loss = train_label_loss, \n",
    "                                                                           acc = train_label_acc, \n",
    "                                                                           fi_score = train_label_fi_score, \n",
    "                                                                           data_loder = train_loder, \n",
    "                                                                           total = total)\n",
    "        \n",
    "        train_mask_loss, train_mask_acc, train_mask_fi_score = get_loss(loss = train_mask_loss, \n",
    "                                                                           acc = train_mask_acc, \n",
    "                                                                           fi_score = train_mask_fi_score, \n",
    "                                                                           data_loder = train_loder, \n",
    "                                                                           total = total)\n",
    "        \n",
    "        train_gender_loss, train_gender_acc, train_gender_fi_score = get_loss(loss = train_gender_loss, \n",
    "                                                                           acc = train_gender_acc, \n",
    "                                                                           fi_score = train_gender_fi_score, \n",
    "                                                                           data_loder = train_loder, \n",
    "                                                                           total = total)\n",
    "        \n",
    "        train_age_loss, train_age_acc, train_age_fi_score = get_loss(loss = train_age_loss, \n",
    "                                                                           acc = train_age_acc, \n",
    "                                                                           fi_score = train_age_fi_score, \n",
    "                                                                           data_loder = train_loder, \n",
    "                                                                           total = total)\n",
    "        \n",
    "        # 평가\n",
    "        total = 0\n",
    "        for images, labels, ages, genders, masks in val_loder:\n",
    "            total += labels.size(0)\n",
    "            \n",
    "            val_label_loss, val_label_acc, val_label_fi_score = batch_eval(model = label_model, \n",
    "                                                                           criterion = criterion, \n",
    "                                                                           images = images, \n",
    "                                                                           targets = labels, \n",
    "                                                                           val_loss = val_label_loss, \n",
    "                                                                           val_acc = val_label_acc, \n",
    "                                                                           val_fi_score = val_label_fi_score)\n",
    "            \n",
    "            val_mask_loss, val_mask_acc, val_mask_fi_score = batch_eval(model = mask_model, \n",
    "                                                                           criterion = criterion, \n",
    "                                                                           images = images, \n",
    "                                                                           targets = masks, \n",
    "                                                                           val_loss = val_mask_loss, \n",
    "                                                                           val_acc = val_mask_acc, \n",
    "                                                                           val_fi_score = val_mask_fi_score)\n",
    "            \n",
    "            val_gender_loss, val_gender_acc, val_gender_fi_score = batch_eval(model = gender_model, \n",
    "                                                                           criterion = criterion, \n",
    "                                                                           images = images, \n",
    "                                                                           targets = genders, \n",
    "                                                                           val_loss = val_gender_loss, \n",
    "                                                                           val_acc = val_gender_acc, \n",
    "                                                                           val_fi_score = val_gender_fi_score)\n",
    "            \n",
    "            val_age_loss, val_age_acc, val_age_fi_score = batch_eval(model = age_model, \n",
    "                                                                           criterion = criterion, \n",
    "                                                                           images = images, \n",
    "                                                                           targets = ages, \n",
    "                                                                           val_loss = val_age_loss, \n",
    "                                                                           val_acc = val_age_acc, \n",
    "                                                                           val_fi_score = val_age_fi_score)\n",
    "            \n",
    "        \n",
    "        # total_loss 계산\n",
    "        val_label_loss, val_label_acc, val_label_fi_score = get_loss(loss = val_label_loss, \n",
    "                                                                           acc = val_label_acc, \n",
    "                                                                           fi_score = val_label_fi_score, \n",
    "                                                                           data_loder = val_loder, \n",
    "                                                                           total = total)\n",
    "        \n",
    "        val_mask_loss, val_mask_acc, val_mask_fi_score = get_loss(loss = val_mask_loss, \n",
    "                                                                           acc = val_mask_acc, \n",
    "                                                                           fi_score = val_mask_fi_score, \n",
    "                                                                           data_loder = val_loder, \n",
    "                                                                           total = total)\n",
    "        \n",
    "        val_gender_loss, val_gender_acc, val_gender_fi_score = get_loss(loss = val_gender_loss, \n",
    "                                                                           acc = val_gender_acc, \n",
    "                                                                           fi_score = val_gender_fi_score, \n",
    "                                                                           data_loder = val_loder,\n",
    "                                                                           total = total)\n",
    "        \n",
    "        val_age_loss, val_age_acc, val_age_fi_score = get_loss(loss = val_age_loss, \n",
    "                                                                           acc = val_age_acc, \n",
    "                                                                           fi_score = val_age_fi_score, \n",
    "                                                                           data_loder = val_loder, \n",
    "                                                                           total = total)\n",
    "    \n",
    "        \n",
    "        # 학습 결과 출력\n",
    "        model_li = ['label', 'mask', 'gender', 'age']\n",
    "        for idx, (train_loss, train_acc, train_f1, val_loss, val_acc, val_fi) in enumerate([\n",
    "                [train_label_loss, train_label_acc, train_label_fi_score, val_label_loss, val_label_acc, val_label_fi_score],\n",
    "                [train_mask_loss, train_mask_acc, train_mask_fi_score, val_mask_loss, val_mask_acc, val_mask_fi_score],\n",
    "                [train_gender_loss, train_gender_acc, train_gender_fi_score, val_gender_loss, val_gender_acc, val_gender_fi_score],\n",
    "                [train_age_loss, train_age_acc, train_age_fi_score, val_age_loss, val_age_acc, val_age_fi_score],\n",
    "            ]):\n",
    "            \n",
    "            print(f'{now_fold_num + 1}fold, epoch: {epoch}, model: {model_li[idx]}, train_loss: {train_loss:.4f}, train_acc: {train_acc:.4f}, train_f1: {train_f1:.4f}, val_loss: {val_loss:.4f}, val_acc: {val_acc:.4f}, val_fi: {val_fi:.4f}')\n",
    "        \n",
    "        epoch_end_time = time.time()\n",
    "        \n",
    "        print(f'{now_fold_num + 1}fold, epoch: {epoch}, 학습시간: {epoch_end_time - epoch_start_time} \\n')\n",
    "        \n",
    "        \n",
    "        # 스케줄러\n",
    "        label_scheduler.step(val_label_loss)\n",
    "        mask_scheduler.step(val_mask_loss)\n",
    "        gender_scheduler.step(val_gender_loss)\n",
    "        age_scheduler.step(val_age_loss)\n",
    "        \n",
    "        \n",
    "        # 모델 저장\n",
    "        if label_besf_fi < val_label_fi_score:\n",
    "            label_besf_fi = val_label_fi_score\n",
    "            torch.save(label_model.state_dict(), model_dir + f'{now_fold_num + 1}fold_label_ResNet.pt')\n",
    "        \n",
    "        if mask_besf_fi < val_mask_fi_score:\n",
    "            mask_besf_fi = val_mask_fi_score\n",
    "            torch.save(mask_model.state_dict(), model_dir + f'{now_fold_num + 1}fold_mask_ResNet.pt')\n",
    "            \n",
    "        if gender_besf_fi < val_gender_fi_score:\n",
    "            gender_besf_fi = val_gender_fi_score\n",
    "            torch.save(gender_model.state_dict(), model_dir + f'{now_fold_num + 1}fold_gender_ResNet.pt')\n",
    "            \n",
    "        if age_besf_fi < val_age_fi_score:\n",
    "            age_besf_fi = val_age_fi_score\n",
    "            torch.save(age_model.state_dict(), model_dir + f'{now_fold_num + 1}fold_age_ResNet.pt')\n",
    "    \n",
    "    fold_end_time = time.time()\n",
    "    \n",
    "    print(f'{now_fold_num + 1}fold 훈련 시간: {fold_end_time - fold_start_time}')\n",
    "\n",
    "total_end_time = time.time()\n",
    "print(f'총 훈련 시간: {total_end_time - total_start_time}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0bd265-7020-45cd-9217-e1b785081c1c",
   "metadata": {},
   "source": [
    "# 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eccd2644-817f-4168-8143-841eded54697",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "평가 및 예측\n",
    "\n",
    "'''\n",
    "\n",
    "skf = StratifiedKFold(n_splits = fold_num, random_state = seed, shuffle = True)\n",
    "\n",
    "# 앙상블 데이터 저장용\n",
    "train_oof = np.zeros((train_set.shape[0], 4))\n",
    "test_oof = np.zeros((test_set.shape[0], 4))\n",
    "submission_oof = np.zeros((submission.shape[0], 4))\n",
    "\n",
    "# test 데이터 정의\n",
    "test_dataset = CustomDataset(df = test_set, \n",
    "                            transform = transform, \n",
    "                            train = True)\n",
    "\n",
    "test_loder = DataLoader(test_dataset,\n",
    "                        batch_size = batch_size,\n",
    "                        shuffle = False,)\n",
    "\n",
    "test_label_oof = np.zeros((test_set.shape[0], 18))\n",
    "test_mask_oof = np.zeros((test_set.shape[0], 3))\n",
    "test_gender_oof = np.zeros((test_set.shape[0], 2))\n",
    "test_age_oof = np.zeros((test_set.shape[0], 3))\n",
    "\n",
    "# submission 데이터 정의\n",
    "submission_dataset = CustomDataset(df = submission, \n",
    "                            transform = transform, \n",
    "                            train = False)\n",
    "\n",
    "submission_loder = DataLoader(submission_dataset,\n",
    "                        batch_size = batch_size,\n",
    "                        shuffle = False,)\n",
    "\n",
    "submission_label_oof = np.zeros((submission.shape[0], 18))\n",
    "submission_mask_oof = np.zeros((submission.shape[0], 3))\n",
    "submission_gender_oof = np.zeros((submission.shape[0], 2))\n",
    "submission_age_oof = np.zeros((submission.shape[0], 3))\n",
    "\n",
    "# 예측\n",
    "for now_fold_num, (trn_idx, val_idx) in tqdm(enumerate(skf.split(train_set, train_set['label']))):\n",
    "    val_df = train_set.iloc[val_idx, :]\n",
    "    \n",
    "    val_dataset = CustomDataset(df = val_df, \n",
    "                                transform = transform, \n",
    "                                train = True)\n",
    "    \n",
    "    val_loder = DataLoader(val_dataset,\n",
    "                            batch_size = batch_size,\n",
    "                            shuffle = False,)\n",
    "    \n",
    "    \n",
    "    # 모델 로드\n",
    "    label_model = ResNet(block = BasicBlock, num_blocks = [2, 2, 2, 2], num_classes = 18).to(device)\n",
    "    label_model.load_state_dict(torch.load(model_dir + f'{now_fold_num + 1}fold_label_ResNet.pt', map_location = device))\n",
    "    \n",
    "    mask_model = ResNet(block = BasicBlock, num_blocks = [2, 2, 2, 2], num_classes = 3).to(device)\n",
    "    mask_model.load_state_dict(torch.load(model_dir + f'{now_fold_num + 1}fold_mask_ResNet.pt', map_location = device))\n",
    "    \n",
    "    gender_model = ResNet(block = BasicBlock, num_blocks = [2, 2, 2, 2], num_classes = 2).to(device)\n",
    "    gender_model.load_state_dict(torch.load(model_dir + f'{now_fold_num + 1}fold_gender_ResNet.pt', map_location = device))\n",
    "    \n",
    "    age_model = ResNet(block = BasicBlock, num_blocks = [2, 2, 2, 2], num_classes = 3).to(device)\n",
    "    age_model.load_state_dict(torch.load(model_dir + f'{now_fold_num + 1}fold_age_ResNet.pt', map_location = device))    \n",
    "    \n",
    "    # train_oof\n",
    "    label_pred_li, mask_pred_li, gender_pred_li, age_pred_li = [], [], [], []\n",
    "    with torch.no_grad():\n",
    "        for images, _, _, _, _ in val_loder:\n",
    "            images = images.to(device)\n",
    "            \n",
    "            label = label_model(images).argmax(dim=-1)\n",
    "            mask = mask_model(images).argmax(dim=-1)\n",
    "            gender = gender_model(images).argmax(dim=-1)\n",
    "            age = age_model(images).argmax(dim=-1)\n",
    "            \n",
    "            label_pred_li.extend(label.cpu().numpy())\n",
    "            mask_pred_li.extend(mask.cpu().numpy())\n",
    "            gender_pred_li.extend(gender.cpu().numpy())\n",
    "            age_pred_li.extend(age.cpu().numpy())\n",
    "    \n",
    "    train_oof[val_idx, 0] = label_pred_li\n",
    "    train_oof[val_idx, 1] = mask_pred_li\n",
    "    train_oof[val_idx, 2] = gender_pred_li\n",
    "    train_oof[val_idx, 3] = age_pred_li\n",
    "    \n",
    "    # test_oof\n",
    "    label_pred_li, mask_pred_li, gender_pred_li, age_pred_li = [], [], [], []\n",
    "    with torch.no_grad():\n",
    "        for images, _, _, _, _ in test_loder:\n",
    "            images = images.to(device)\n",
    "            \n",
    "            label = label_model(images).softmax(1)\n",
    "            mask = mask_model(images).softmax(1)\n",
    "            gender = gender_model(images).softmax(1)\n",
    "            age = age_model(images).softmax(1)\n",
    "            \n",
    "            label_pred_li.append(label.cpu().numpy())\n",
    "            mask_pred_li.append(mask.cpu().numpy())\n",
    "            gender_pred_li.append(gender.cpu().numpy())\n",
    "            age_pred_li.append(age.cpu().numpy())\n",
    "\n",
    "    test_label_oof += np.concatenate(label_pred_li) / fold_num\n",
    "    test_mask_oof += np.concatenate(mask_pred_li)/ fold_num\n",
    "    test_gender_oof +=np.concatenate(gender_pred_li) / fold_num\n",
    "    test_age_oof += np.concatenate(age_pred_li) / fold_num\n",
    "    \n",
    "    # submission_oof\n",
    "    label_pred_li, mask_pred_li, gender_pred_li, age_pred_li = [], [], [], []\n",
    "    with torch.no_grad():\n",
    "        for images in submission_loder:\n",
    "            images = images.to(device)\n",
    "            \n",
    "            label = label_model(images).softmax(1)\n",
    "            mask = mask_model(images).softmax(1)\n",
    "            gender = gender_model(images).softmax(1)\n",
    "            age = age_model(images).softmax(1)\n",
    "            \n",
    "            label_pred_li.append(label.cpu().numpy())\n",
    "            mask_pred_li.append(mask.cpu().numpy())\n",
    "            gender_pred_li.append(gender.cpu().numpy())\n",
    "            age_pred_li.append(age.cpu().numpy())\n",
    "\n",
    "    submission_label_oof += np.concatenate(label_pred_li) / fold_num\n",
    "    submission_mask_oof += np.concatenate(mask_pred_li)/ fold_num\n",
    "    submission_gender_oof +=np.concatenate(gender_pred_li) / fold_num\n",
    "    submission_age_oof += np.concatenate(age_pred_li) / fold_num\n",
    "\n",
    "test_oof[:, 0] = test_label_oof.argmax(1).tolist()\n",
    "test_oof[:, 1] = test_mask_oof.argmax(1).tolist()\n",
    "test_oof[:, 2] = test_gender_oof.argmax(1).tolist()\n",
    "test_oof[:, 3] = test_age_oof.argmax(1).tolist()\n",
    "\n",
    "submission_oof[:, 0] = submission_label_oof.argmax(1).tolist()\n",
    "submission_oof[:, 1] = submission_mask_oof.argmax(1).tolist()\n",
    "submission_oof[:, 2] = submission_gender_oof.argmax(1).tolist()\n",
    "submission_oof[:, 3] = submission_age_oof.argmax(1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9396c31-fdcf-4ed7-b082-4dfebcce15a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_li = ['label', 'mask', 'gender_group', 'age_group']\n",
    "\n",
    "ensemble_train_df = pd.DataFrame(train_oof, columns = col_li).astype(int)\n",
    "ensemble_train_df['ensemble_label'] = ensemble_train_df['mask'] * 6 + ensemble_train_df['gender_group'] * 3 + ensemble_train_df['age_group']\n",
    "\n",
    "ensemble_test_df = pd.DataFrame(test_oof, columns = col_li).astype(int)\n",
    "ensemble_test_df['ensemble_label'] = ensemble_test_df['mask'] * 6 + ensemble_test_df['gender_group'] * 3 + ensemble_test_df['age_group']\n",
    "\n",
    "ensemble_submission_df = pd.DataFrame(submission_oof, columns = col_li)\n",
    "ensemble_submission_df['ensemble_label'] = ensemble_submission_df['mask'] * 6 + ensemble_submission_df['gender_group'] * 3 + ensemble_submission_df['age_group']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e88ab8f-dfce-47dd-ac49-27d08f508ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "confusion_matrix and f1\n",
    "\n",
    "'''\n",
    "\n",
    "col_li = ['label', 'mask', 'gender_group', 'age_group', 'ensemble_label']\n",
    "\n",
    "for col in col_li:\n",
    "    if col != 'ensemble_label':\n",
    "        train_y_true = train_set[col].values\n",
    "        train_y_pred = ensemble_train_df[col].values\n",
    "        \n",
    "        test_y_true = test_set[col].values\n",
    "        test_y_pred = ensemble_test_df[col].values\n",
    "    \n",
    "    else:\n",
    "        train_y_true = train_set['label'].values\n",
    "        train_y_pred = ensemble_train_df[col].values\n",
    "        \n",
    "        test_y_true = test_set['label'].values\n",
    "        test_y_pred = ensemble_test_df[col].values        \n",
    "    \n",
    "    \n",
    "    train_f1 = get_f1_score(y_true = train_y_true,  y_pred = train_y_pred)\n",
    "    test_f1 = get_f1_score(y_true = test_y_true, y_pred = test_y_pred)\n",
    "    \n",
    "    train_confusion_matrix = pd.DataFrame((confusion_matrix(y_true = train_y_true, y_pred = train_y_pred)))\n",
    "    test_confusion_matrix = pd.DataFrame((confusion_matrix(y_true = test_y_true, y_pred = test_y_pred)))\n",
    "    \n",
    "    print(f'{col} train confusion_matrix')\n",
    "    display(train_confusion_matrix)\n",
    "    \n",
    "    print(f'{col} test confusion_matrix')\n",
    "    display(test_confusion_matrix)\n",
    "    print(f'train fi : {train_f1}, test_f1 fi : {test_f1}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc7a0ca-ac0f-4ca7-87a0-e36fa0e8ba18",
   "metadata": {},
   "source": [
    "# 제출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87269aad-26ab-4850-9a9f-ca2187562cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측에 사용할 라벨 결정\n",
    "submission['ans'] = ensemble_submission_df['ensemble_label'].astype(int).values\n",
    "\n",
    "# 제출할 파일을 저장합니다.\n",
    "submission.to_csv(os.path.join(submission_data_dir, 'submission.csv'), index=False)\n",
    "print('test inference is done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d885390b-ed86-40c0-93df-0cc85171244a",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486be94b-2352-452a-a623-c743cb0a701b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
