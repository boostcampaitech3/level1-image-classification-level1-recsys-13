{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e5d2c5c-0d38-4e02-bf3c-14e676c7bca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-25 15:17:59.804533: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/conda/lib/python3.8/site-packages/cv2/../../lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2022-02-25 15:17:59.804569: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import torchvision.models as models\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import gc\n",
    "import argparse\n",
    "import random\n",
    "from box import Box\n",
    "import cv2\n",
    "import cvlib as cv\n",
    "import albumentations\n",
    "import timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3011f4f1-90cb-47fc-a042-5b4f73054027",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed 고정\n",
    "def seed_everything(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # if use multi-GPU\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a396c963-2529-4d80-89f0-c245b5aa3dc9",
   "metadata": {},
   "source": [
    "# 데이터 전처리 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0add8f5-dd45-4cf1-9b94-3536fd5d3261",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ages 생성\n",
    "def get_ages(x):\n",
    "    if x < 30: return 0\n",
    "    elif x < 60: return 1\n",
    "    else: return 2\n",
    "\n",
    "# genders 생성\n",
    "def get_genders(x):\n",
    "    if x == 'male': return 0\n",
    "    else: return 1\n",
    "\n",
    "# masks 생성\n",
    "def get_masks(x):\n",
    "    if x == 'normal': return 2\n",
    "    elif x == 'incorrect_mask': return 1\n",
    "    else: return 0\n",
    "\n",
    "# age_cats 생성\n",
    "def get_age_cats(x):\n",
    "    if x < 20: return 0\n",
    "    elif x < 30: return 1\n",
    "    elif x < 40: return 2\n",
    "    elif x < 50: return 3\n",
    "    elif x < 60: return 4\n",
    "    else: return 5\n",
    "\n",
    "# labels 생성\n",
    "def get_labels(masks, genders, ages):\n",
    "    return masks * 6 + genders * 3 + ages\n",
    "\n",
    "# label_cats 생성\n",
    "def get_label_cats(masks, genders, ages):\n",
    "    return masks * 12 + genders * 6 + ages\n",
    "\n",
    "# 마스크 이상치 변경\n",
    "def swap_mask(swap_li : list, df : pd.DataFrame) -> pd.DataFrame:\n",
    "    swap_df = df.copy()\n",
    "    for swap_id in swap_li:\n",
    "        _swap_df = swap_df[swap_df['id'] == swap_id]\n",
    "        \n",
    "        normal_swap_df = _swap_df[_swap_df['mask'] == 'normal']\n",
    "        incorrect_mask_swap_df = _swap_df[_swap_df['mask'] == 'incorrect_mask']\n",
    "        \n",
    "        normal_path = normal_swap_df['path'].values[0]\n",
    "        incorrect_mask_path = incorrect_mask_swap_df['path'].values[0]\n",
    "        \n",
    "        swap_df.loc[normal_swap_df.index, 'path'] = incorrect_mask_path\n",
    "        swap_df.loc[incorrect_mask_swap_df.index, 'path'] = normal_path\n",
    "    \n",
    "    return swap_df\n",
    "\n",
    "# train_df + mask 결측치 처리\n",
    "def make_train_df(df : pd.DataFrame, swap_mask_li : list, cfg) -> pd.DataFrame:\n",
    "    train_df = []\n",
    "    \n",
    "    for line in df.iloc:\n",
    "        for file in list(os.listdir(os.path.join(cfg.train_image_dir, line['path']))):\n",
    "            if file[0] == '.':\n",
    "                continue\n",
    "            \n",
    "            mask = file.split('.')[0]\n",
    "            gender = line['gender']\n",
    "            age = line['age']\n",
    "            \n",
    "            masks = get_masks(mask)\n",
    "            genders = get_genders(gender)\n",
    "            ages = get_ages(age)\n",
    "            age_cats = get_age_cats(age)\n",
    "            \n",
    "            data = {\n",
    "                'id' : line['id'],\n",
    "                'mask' : mask,\n",
    "                'gender' : gender,\n",
    "                'age' : age,\n",
    "                'masks' : masks,\n",
    "                'genders' : genders,\n",
    "                'ages' : ages,\n",
    "                'age_cats' : age_cats,\n",
    "                'labels': get_labels(masks = masks, genders = genders, ages = ages),\n",
    "                'label_cats': get_label_cats(masks = masks, genders = genders, ages = age_cats),\n",
    "                'path': os.path.join(cfg.train_image_dir, line['path'], file),\n",
    "            }\n",
    "            \n",
    "            train_df.append(data)\n",
    "            \n",
    "    train_df = pd.DataFrame(train_df)\n",
    "    \n",
    "    train_df['idx'] = train_df.index\n",
    "    \n",
    "    train_df = swap_mask(swap_li = swap_mask_li, df = train_df)\n",
    "    \n",
    "    return train_df\n",
    "\n",
    "# 성별 이상치 처리\n",
    "def swap_gender(swap_li : list, df : pd.DataFrame) -> pd.DataFrame:\n",
    "    swap_df = df.copy()\n",
    "    for swap in swap_li:\n",
    "        swap_id, swap_gender = swap\n",
    "        swap_df.loc[swap_df[swap_df['id'] == swap_id].index, 'gender'] = swap_gender\n",
    "    return swap_df\n",
    "\n",
    "# 사람 나누기 데이터 + 성별 결측치 처리\n",
    "def preprocessing_df(df : pd.DataFrame, swap_gender_li : list) -> pd.DataFrame:\n",
    "    \n",
    "    preprocessing_df = df.copy()\n",
    "    preprocessing_df = swap_gender(swap_li = swap_gender_li, df = preprocessing_df)\n",
    "    \n",
    "    preprocessing_df['ages'] = preprocessing_df['age'].apply(lambda x : get_ages(x))\n",
    "    preprocessing_df['genders'] = preprocessing_df['gender'].apply(lambda x : get_genders(x))\n",
    "    \n",
    "    preprocessing_df['cv_taget_col'] = 'ages' + '_' + preprocessing_df['ages'].astype(str) + '_' + 'genders' + '_' + preprocessing_df['genders'].astype(str)\n",
    "    \n",
    "    return preprocessing_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6466c6-37e1-4449-9a6d-bfef756b66d9",
   "metadata": {},
   "source": [
    "# 이상치 시각화 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8603a8a-baef-40cc-b809-57d25f065959",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이상치 이미지 시각화\n",
    "def show_img(img_id_li, df, cfg):\n",
    "    for img_id in img_id_li:\n",
    "        get_df = df[df['id'] == img_id]\n",
    "        \n",
    "        img_age = get_df['age'].tolist()[0]\n",
    "        img_gender = get_df['gender'].tolist()[0]\n",
    "        \n",
    "        img_path = get_df['path'].tolist()[0]\n",
    "        img_path = os.path.join(cfg.train_image_dir, img_path)\n",
    "        img_name_li = sorted(list(os.listdir(img_path)))\n",
    "        \n",
    "        fig, ax = plt.subplots(1, 7, figsize = (30, 15))\n",
    "        ax = ax.flatten()\n",
    "        \n",
    "        idx = 0\n",
    "        for _img_name in img_name_li:\n",
    "            if _img_name[0] == '.': continue\n",
    "            \n",
    "            if _img_name.split('.')[0] == 'normal': imag_name = 'normal'\n",
    "            elif _img_name.split('.')[0] == 'incorrect_mask': imag_name = 'incorrect_mask'\n",
    "            else: imag_name = 'mask'\n",
    "            \n",
    "            get_img_path = os.path.join(img_path, _img_name)\n",
    "            \n",
    "            img = Image.open(get_img_path)\n",
    "            img = np.array(img)\n",
    "            ax[idx].imshow(img)\n",
    "            ax[idx].set_title(f'{img_id} / {img_age} / {img_gender} / {imag_name}')\n",
    "            ax[idx].set_xticks([])\n",
    "            ax[idx].set_yticks([])\n",
    "            idx += 1\n",
    "            \n",
    "        plt.show()\n",
    "\n",
    "# image path로 이미지 시각화\n",
    "def path_li_show_img(path_li):\n",
    "    fig, ax = plt.subplots(1, 7, figsize = (30, 15))\n",
    "    ax = ax.flatten()\n",
    "    idx = 0\n",
    "    for path in path_li:\n",
    "        image_name = path.split('/')[-1]\n",
    "        img = Image.open(path)\n",
    "        img = np.array(img)\n",
    "        ax[idx].imshow(img)\n",
    "        ax[idx].set_title(f'{image_name}')\n",
    "        ax[idx].set_xticks([])\n",
    "        ax[idx].set_yticks([])\n",
    "        idx += 1\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62553119-8862-4f1f-bdd5-5da4de1a0a45",
   "metadata": {},
   "source": [
    "# 데이터 설정 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44405254-ea08-48ba-9396-1ee689f0b786",
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_idx 생성\n",
    "def get_val_idx(df : pd.DataFrame, target_col : str):\n",
    "    skf = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 22)\n",
    "    for trn_idx, val_idx in skf.split(df, df[target_col]):\n",
    "        yield val_idx\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, df : pd.DataFrame, cfg, transform : transforms = None, mode : bool = True):\n",
    "        self.mode = mode\n",
    "        self.df = df\n",
    "        if self.mode:\n",
    "            self.img_paths = self.df['path'].tolist()\n",
    "            self.targets = self.df[cfg.tagets_col].tolist()\n",
    "            self.split_targets = self.df[cfg.split_col].tolist()\n",
    "        else:\n",
    "            self.img_paths = [os.path.join(cfg.submission_image_dir, img_id) for img_id in self.df.ImageID]\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = Image.open(self.img_paths[index])\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        # 이 부분에 해당 라벨에 따른 데이터 변환 여부 추가\n",
    "        # val 데이터의 경우 데이터 변환이 일어나면 안되기 때문에\n",
    "        # if self.데이터 변환해주는 transform:\n",
    "        #     if self.targets[index].data == labels: <- 확률적으로\n",
    "        #          image = self.데이터 변환해주는 transform(image)\n",
    "        # 데이터 변환\n",
    "        \n",
    "        if self.mode:\n",
    "            targets = torch.tensor(self.targets[index])\n",
    "            return image, targets\n",
    "        \n",
    "        else: return image\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)\n",
    "\n",
    "class StratifiedSampler(torch.utils.data.Sampler):\n",
    "    \"\"\"Stratified batch sampling\n",
    "    Provides equal representation of target classes in each batch\n",
    "    \"\"\"\n",
    "    def __init__(self, y, batch_size, shuffle=True):\n",
    "        if torch.is_tensor(y):\n",
    "            y = y.cpu().numpy()\n",
    "        assert len(y.shape) == 1, 'label array must be 1D'\n",
    "        n_batches = int(len(y) / batch_size)\n",
    "        self.skf = StratifiedKFold(n_splits = n_batches, shuffle = shuffle)\n",
    "        self.X = torch.randn(len(y),1).numpy()\n",
    "        self.y = y\n",
    "        self.shuffle = shuffle\n",
    "\n",
    "    def __iter__(self):\n",
    "        if self.shuffle:\n",
    "            self.skf.random_state = torch.randint(0,int(1e8),size=()).item()\n",
    "        for train_idx, test_idx in self.skf.split(self.X, self.y):\n",
    "            yield test_idx\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "931c23a0-236a-4bed-9106-6c321c86f9af",
   "metadata": {},
   "source": [
    "# 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7a50293-f658-432a-a858-5036b9593c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CreateModel(nn.Module):\n",
    "    def __init__(self, cfg , pretrained : bool = True):\n",
    "        super(CreateModel, self).__init__()\n",
    "        self.model = timm.create_model(cfg.timm_model_name, pretrained = pretrained, num_classes = cfg.num_classes)\n",
    "\n",
    "    def forward(self, img):\n",
    "        out = self.model(img)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5fc2534a-83ba-42f8-99a6-0a421bfaad7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_f1_score(y_true, y_pred):\n",
    "    return f1_score(y_true, y_pred, average='macro')\n",
    "\n",
    "def get_acc_score(y_true, y_pred):\n",
    "    return accuracy_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2159e73-219e-4a6b-ab16-5a927be48725",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_train(model, optimizer, criterion, data_loader):\n",
    "    model.train()\n",
    "    \n",
    "    train_loss = 0\n",
    "    real_pred_li = []\n",
    "    label_pred_li = []\n",
    "    \n",
    "    for images, targets in data_loader:\n",
    "        images, targets = images.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # GA 추가시 아래 부분에 추가하기\n",
    "        #############################\n",
    "        \n",
    "        benign_outputs = model(images)\n",
    "        loss = criterion(benign_outputs, targets)\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        predicted = benign_outputs.argmax(dim=-1)\n",
    "        \n",
    "        label_pred_li.extend(predicted.detach().cpu().numpy())\n",
    "        real_pred_li.extend(targets.cpu().numpy())\n",
    "        \n",
    "#     label_pred_li = [label_cats2labels[i] for i in label_pred_li]\n",
    "#     real_pred_li = [label_cats2labels[i] for i in real_pred_li]\n",
    "    \n",
    "    train_loss /= len(data_loader)\n",
    "    train_acc = get_acc_score(y_true = real_pred_li, y_pred = label_pred_li)\n",
    "    train_fi_score = get_f1_score(y_true = real_pred_li, y_pred = label_pred_li)\n",
    "\n",
    "    return train_loss, train_acc, train_fi_score\n",
    "\n",
    "def model_eval(model, criterion, data_loader):\n",
    "    model.eval()\n",
    "    \n",
    "    val_loss = 0\n",
    "    real_pred_li = []\n",
    "    label_pred_li = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, targets in data_loader:\n",
    "            images, targets = images.to(device), targets.to(device)\n",
    "\n",
    "            benign_outputs = model(images)\n",
    "            loss = criterion(benign_outputs, targets)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            predicted = benign_outputs.argmax(dim=-1)\n",
    "        \n",
    "            label_pred_li.extend(predicted.cpu().numpy())\n",
    "            real_pred_li.extend(targets.cpu().numpy())\n",
    "    \n",
    "#     label_pred_li = [label_cats2labels[i] for i in label_pred_li]\n",
    "#     real_pred_li = [label_cats2labels[i] for i in real_pred_li]\n",
    "    \n",
    "    val_loss /= len(data_loader)\n",
    "    val_acc = get_acc_score(y_true = real_pred_li, y_pred = label_pred_li)\n",
    "    val_fi_score = get_f1_score(y_true = real_pred_li, y_pred = label_pred_li)\n",
    "   \n",
    "    return val_loss, val_acc, val_fi_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57b3b262-1703-4583-a937-28c5db3bb5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd9b38e3-426b-4f06-b500-e3631320aac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_val_pred_li(model, data_loader):\n",
    "    model.eval()\n",
    "    real_pred_li = []\n",
    "    label_pred_li = []\n",
    "    ensemble_pred_li = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, targets in data_loader:\n",
    "            images = images.to(device)\n",
    "            output = model(images)\n",
    "            \n",
    "            label = output.argmax(dim=-1)\n",
    "            label_pred_li.extend(label.cpu().numpy())\n",
    "            \n",
    "            ensemble_label = output.softmax(1)\n",
    "            ensemble_pred_li.append(ensemble_label.cpu().numpy())\n",
    "            \n",
    "            real_pred_li.extend(targets.cpu().numpy())\n",
    "            \n",
    "#     label_pred_li = [label_cats2labels[i] for i in label_pred_li]\n",
    "#     real_pred_li = [label_cats2labels[i] for i in real_pred_li]\n",
    "    \n",
    "    return label_pred_li, np.concatenate(ensemble_pred_li), real_pred_li\n",
    "\n",
    "def get_submission_pred_li(model, data_loader):\n",
    "    model.eval()\n",
    "    label_pred_li = []\n",
    "    ensemble_pred_li = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images in data_loader:\n",
    "            images = images.to(device)\n",
    "            output = model(images)\n",
    "            \n",
    "            label = output.argmax(dim=-1)\n",
    "            label_pred_li.extend(label.cpu().numpy())\n",
    "            \n",
    "            ensemble_label = output.softmax(1)\n",
    "            ensemble_pred_li.append(ensemble_label.cpu().numpy())\n",
    "            \n",
    "#     label_pred_li = [label_cats2labels[i] for i in label_pred_li]\n",
    "    \n",
    "    return label_pred_li, np.concatenate(ensemble_pred_li)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aefc2e44-fedf-4a9c-8e71-ea8f077bf8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, weight=None, gamma=2., reduction='mean'):\n",
    "        nn.Module.__init__(self)\n",
    "        self.weight = weight\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, input_tensor, target_tensor):\n",
    "        log_prob = F.log_softmax(input_tensor, dim=-1)\n",
    "        prob = torch.exp(log_prob)\n",
    "        return F.nll_loss(\n",
    "            ((1 - prob) ** self.gamma) * log_prob,\n",
    "            target_tensor,\n",
    "            weight=self.weight,\n",
    "            reduction=self.reduction\n",
    "        )\n",
    "\n",
    "\n",
    "class LabelSmoothingLoss(nn.Module):\n",
    "    def __init__(self, classes=3, smoothing=0.0, dim=-1):\n",
    "        super(LabelSmoothingLoss, self).__init__()\n",
    "        self.confidence = 1.0 - smoothing\n",
    "        self.smoothing = smoothing\n",
    "        self.cls = classes\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, pred, target):\n",
    "        pred = pred.log_softmax(dim=self.dim)\n",
    "        with torch.no_grad():\n",
    "            true_dist = torch.zeros_like(pred)\n",
    "            true_dist.fill_(self.smoothing / (self.cls - 1))\n",
    "            true_dist.scatter_(1, target.data.unsqueeze(1), self.confidence)\n",
    "        return torch.mean(torch.sum(-true_dist * pred, dim=self.dim))\n",
    "\n",
    "\n",
    "# https://gist.github.com/SuperShinyEyes/dcc68a08ff8b615442e3bc6a9b55a354\n",
    "class F1Loss(nn.Module):\n",
    "    def __init__(self, classes=3, epsilon=1e-7):\n",
    "        super().__init__()\n",
    "        self.classes = classes\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "        assert y_pred.ndim == 2\n",
    "        assert y_true.ndim == 1\n",
    "        y_true = F.one_hot(y_true, self.classes).to(torch.float32)\n",
    "        y_pred = F.softmax(y_pred, dim=1)\n",
    "\n",
    "        tp = (y_true * y_pred).sum(dim=0).to(torch.float32)\n",
    "        tn = ((1 - y_true) * (1 - y_pred)).sum(dim=0).to(torch.float32)\n",
    "        fp = ((1 - y_true) * y_pred).sum(dim=0).to(torch.float32)\n",
    "        fn = (y_true * (1 - y_pred)).sum(dim=0).to(torch.float32)\n",
    "\n",
    "        precision = tp / (tp + fp + self.epsilon)\n",
    "        recall = tp / (tp + fn + self.epsilon)\n",
    "\n",
    "        f1 = 2 * (precision * recall) / (precision + recall + self.epsilon)\n",
    "        f1 = f1.clamp(min=self.epsilon, max=1 - self.epsilon)\n",
    "        return 1 - f1.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892bc074-57cc-4c87-bb82-20936b25b1cb",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 환경 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac961a79-bcba-46d4-bcc4-435ce0cf453e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이상치 list\n",
    "# swap_gender_li = ['id', '바꿀 성별']\n",
    "# swap_mask_li = ['id']\n",
    "swap_gender_li = [['006359', 'male'], ['006360', 'male'], ['006361', 'male'], ['006362', 'male'], ['006363', 'male'], ['006364', 'male'], ['001498-1', 'female']]\n",
    "swap_mask_li = ['000020', '004418', '005227']\n",
    "\n",
    "config = {\n",
    "    'seed' : 22,\n",
    "    \n",
    "    'image_size' : [512, 384],\n",
    "    'image_normal_mean' : [0.5, 0.5, 0.5],\n",
    "    'image_normal_std' : [0.2, 0.2, 0.2],\n",
    "    \n",
    "    'num_workers' : 3,\n",
    "    'epochs' : 15,\n",
    "    'batch_size' : 128,\n",
    "    'lr' : 0.001,\n",
    "    'oof' : 1,\n",
    "    'num_classes' : 18,\n",
    "    \n",
    "    # cel\n",
    "    # labelsmoothing\n",
    "    # focal\n",
    "    # f1\n",
    "    'loss' : 'f1',\n",
    "    \n",
    "    'train_data_name' : 'train.csv',\n",
    "    'train_data_dir' : '/opt/ml/input/data/train',\n",
    "    'train_image_dir' : '/opt/ml/input/data/train/images',\n",
    "    \n",
    "    'submission_data_name' : 'info.csv',\n",
    "    'submission_data_dir' : '/opt/ml/input/data/eval',\n",
    "    'submission_image_dir' : '/opt/ml/input/data/eval/images',\n",
    "    \n",
    "    \n",
    "    'model_dir' : '/opt/ml/model',\n",
    "    # 저장할 모델병\n",
    "    'model_name' : 'regnety_002_512_384',\n",
    "    \n",
    "    # timm 에 존재하는 모델 이름\n",
    "    'timm_model_name' : 'regnety_002',\n",
    "    \n",
    "    # 학습 타겟\n",
    "    'tagets_col' : 'labels',\n",
    "    'split_col' : 'label_cats',\n",
    "    'cv_taget_col' : 'cv_taget_col',\n",
    "    \n",
    "    # 저장할 파일명\n",
    "    'file_name' : 'nfnet_l0_512_384.csv',\n",
    "}\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "config = Box(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cf47fce1-02a4-4a69-9611-222414bf7fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 변환할 transform\n",
    "from torchvision.transforms import Resize, ToTensor, Normalize, Lambda, RandomHorizontalFlip, ToPILImage\n",
    "\n",
    "def image_face_crop(image):\n",
    "    image = np.array(image)\n",
    "    face, confidence = cv.detect_face(image)\n",
    "    if not face : return image\n",
    "    x, y, w, h = face[0]\n",
    "    H, W, C = image.shape\n",
    "    image = image[max(y - 100, 0) : min(h + 100, H), max(0 , x - 100) : min(w + 100, W)]\n",
    "    return image\n",
    "\n",
    "\n",
    "transform = {\n",
    "        \"train\": transforms.Compose(\n",
    "            [\n",
    "#                 Lambda(image_face_crop),\n",
    "#                 ToPILImage(),\n",
    "                Resize(config.image_size, Image.BILINEAR),\n",
    "                ToTensor(),\n",
    "#                 RandomHorizontalFlip(p = 0.5),\n",
    "                Normalize(mean=config.image_normal_mean, std=config.image_normal_std),\n",
    "            ]\n",
    "        ),  \n",
    "        \"val\": transforms.Compose(\n",
    "            [\n",
    "                Resize(config.image_size, Image.BILINEAR),\n",
    "                ToTensor(),\n",
    "                Normalize(mean=config.image_normal_mean, std=config.image_normal_std),\n",
    "            ]\n",
    "        ),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1966b7e-b676-41fe-a0aa-bf6d233824c6",
   "metadata": {},
   "source": [
    "# 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6c9bfae8-4bda-4749-949b-e3389a6fed43",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(config.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "01270fba-3558-42dc-81e9-e5574e6c963a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(config.train_data_dir, config.train_data_name))\n",
    "submission = pd.read_csv(os.path.join(config.submission_data_dir, config.submission_data_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52932149-7935-4bd5-92bf-1f706d951914",
   "metadata": {},
   "source": [
    "# 이상치 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f13d2daf-b3a7-442e-9d94-16c8d6b96321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_img(img_id_li =['000020', '004418', '005227', '006359', '006360', '006361', '006362', '006363', '006364', '001498-1'], df = df, cfg = config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c589239-662f-4af2-add9-7648b8c77a68",
   "metadata": {},
   "source": [
    "# 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45fb0b8e-eff7-4ace-abce-7e882e9d84d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1fold, epoch: 1, lr: 0.001, train_loss: 0.3322, train_acc: 0.8367, train_f1: 0.6504, val_loss: 0.3396, val_acc: 0.7984, val_fi: 0.6190, 학습시간: 67.09632062911987 \n",
      "\n",
      "0.619002154789489 모델 저장\n",
      "1fold, epoch: 2, lr: 0.001, train_loss: 0.0556, train_acc: 0.9412, train_f1: 0.8483, val_loss: 0.2858, val_acc: 0.8188, val_fi: 0.6992, 학습시간: 67.1609525680542 \n",
      "\n",
      "0.6992423420378966 모델 저장\n",
      "1fold, epoch: 3, lr: 0.001, train_loss: 0.0271, train_acc: 0.9714, train_f1: 0.9297, val_loss: 0.4357, val_acc: 0.7659, val_fi: 0.6746, 학습시간: 67.63016557693481 \n",
      "\n",
      "1fold, epoch: 4, lr: 0.001, train_loss: 0.0273, train_acc: 0.9720, train_f1: 0.9458, val_loss: 0.2533, val_acc: 0.8680, val_fi: 0.6728, 학습시간: 66.16321873664856 \n",
      "\n",
      "1fold, epoch: 5, lr: 0.001, train_loss: 0.0101, train_acc: 0.9891, train_f1: 0.9747, val_loss: 0.2614, val_acc: 0.8794, val_fi: 0.7375, 학습시간: 65.51678133010864 \n",
      "\n",
      "0.7374720833396511 모델 저장\n",
      "1fold, epoch: 6, lr: 0.001, train_loss: 0.0177, train_acc: 0.9833, train_f1: 0.9673, val_loss: 0.3086, val_acc: 0.8487, val_fi: 0.6958, 학습시간: 67.3452525138855 \n",
      "\n",
      "1fold, epoch: 7, lr: 0.001, train_loss: 0.0127, train_acc: 0.9863, train_f1: 0.9665, val_loss: 0.2770, val_acc: 0.8728, val_fi: 0.7362, 학습시간: 66.97562026977539 \n",
      "\n",
      "1fold, epoch: 8, lr: 0.001, train_loss: 0.0131, train_acc: 0.9873, train_f1: 0.9789, val_loss: 0.2746, val_acc: 0.8540, val_fi: 0.7296, 학습시간: 67.30399012565613 \n",
      "\n",
      "1fold, epoch: 9, lr: 0.001, train_loss: 0.0150, train_acc: 0.9847, train_f1: 0.9682, val_loss: 0.3457, val_acc: 0.8619, val_fi: 0.7163, 학습시간: 66.9413595199585 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "pre_df = preprocessing_df(df = df, swap_gender_li = swap_gender_li)\n",
    "train_df = make_train_df(df = pre_df, swap_mask_li = swap_mask_li, cfg = config)\n",
    "\n",
    "all_idx_li = pre_df.index.tolist()\n",
    "val_idx_li = get_val_idx(df = pre_df, target_col = config.cv_taget_col)\n",
    "\n",
    "total_start_time = time.time()\n",
    "\n",
    "for fold_num in range(1, config.oof + 1):\n",
    "    fold_start_time = time.time()\n",
    "    \n",
    "    # trn, val 데이터 셋\n",
    "    val_idx = next(val_idx_li)\n",
    "    trn_idx = list(set(all_idx_li) - set(val_idx.tolist()))\n",
    "    \n",
    "    val_id_df = pre_df.iloc[val_idx, :]\n",
    "    trn_id_df = pre_df.iloc[trn_idx, :]\n",
    "    \n",
    "    val_df = train_df.set_index('id').loc[val_id_df['id'].tolist(), :].reset_index()\n",
    "    trn_df = train_df.set_index('id').loc[trn_id_df['id'].tolist(), :].reset_index()\n",
    "    \n",
    "    # 이 부분에 클래스가 적은 데이터 증강 함수 추가\n",
    "    ########################################3\n",
    "    \n",
    "    # 배치 단위 데이터 생성 부분\n",
    "    #########################\n",
    "    \n",
    "    \n",
    "    # dataset 구축\n",
    "    trn_dataset = CustomDataset(df = trn_df,\n",
    "                                cfg = config,\n",
    "                                transform = transform['train'],\n",
    "                                mode = True,\n",
    "                               )\n",
    "    \n",
    "    train_loder = DataLoader(trn_dataset,\n",
    "                           batch_size = config.batch_size,\n",
    "                           num_workers = config.num_workers,\n",
    "                           shuffle = True,\n",
    "                            )\n",
    "    \n",
    "    \n",
    "#     sampler = StratifiedSampler(y = np.array(trn_dataset.split_targets), \n",
    "#                                 batch_size = config.batch_size, \n",
    "#                                 shuffle = True)\n",
    "    \n",
    "#     train_loder = DataLoader(trn_dataset,\n",
    "#                              num_workers = config.num_workers,\n",
    "#                              batch_sampler = sampler)\n",
    "    \n",
    "    \n",
    "    val_dataset = CustomDataset(df = val_df,\n",
    "                                cfg = config,\n",
    "                                transform = transform['val'],\n",
    "                                mode = True,)\n",
    "    \n",
    "    val_loder = DataLoader(val_dataset,\n",
    "                           batch_size = config.batch_size,\n",
    "                           num_workers = config.num_workers,\n",
    "                           shuffle = False,)\n",
    "    \n",
    "    # 모델 정의\n",
    "    model = CreateModel(cfg = config, pretrained = True).to(device)\n",
    "\n",
    "    # loss 설정\n",
    "    if config.loss == 'cel':\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "    elif config.loss == 'labelsmoothing':\n",
    "        criterion = LabelSmoothingLoss(classes=config.num_classes, smoothing=0.2, dim=-1)\n",
    "    elif config.loss == 'focal':\n",
    "        criterion = FocalLoss(weight=None, gamma=2., reduction='mean')\n",
    "    elif config.loss == 'f1':\n",
    "        criterion = F1Loss(classes=config.num_classes, epsilon=1e-7)\n",
    "    else:\n",
    "        print('not loss')\n",
    "    \n",
    "    # optimizer 설정\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=config.lr)\n",
    "    \n",
    "    # scheduler 설정\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor = 0.1, eps = 1e-09, patience = 5)\n",
    "   \n",
    "    # besf_metric 설정\n",
    "    besf_fi = 0\n",
    "    \n",
    "    for epoch in range(1, config.epochs + 1):\n",
    "        epoch_start_time = time.time()\n",
    "        \n",
    "        train_loss, train_acc, train_fi_score = model_train(model = model, \n",
    "                                                            optimizer = optimizer, \n",
    "                                                            criterion = criterion, \n",
    "                                                            data_loader = train_loder)\n",
    "        \n",
    "        val_loss, val_acc, val_fi_score, = model_eval(model = model,\n",
    "                                                      criterion = criterion,\n",
    "                                                      data_loader = val_loder)\n",
    "        \n",
    "        # 학습률\n",
    "        now_lr = get_lr(optimizer = optimizer)\n",
    "        \n",
    "        epoch_end_time = time.time()\n",
    "        \n",
    "        print(f'''{fold_num}fold, epoch: {epoch}, lr: {now_lr}, train_loss: {train_loss:.4f}, train_acc: {train_acc:.4f}, train_f1: {train_fi_score:.4f}, val_loss: {val_loss:.4f}, val_acc: {val_acc:.4f}, val_fi: {val_fi_score:.4f}, 학습시간: {epoch_end_time - epoch_start_time} \\n''')\n",
    "\n",
    "        # 스케줄러\n",
    "        scheduler.step(val_loss)\n",
    "        \n",
    "        # 모델 저장\n",
    "        if besf_fi < val_fi_score:\n",
    "            besf_fi = val_fi_score\n",
    "            torch.save(model.state_dict(), os.path.join(config.model_dir, f'{fold_num}fold_{config.model_name}.pt'))\n",
    "            print(besf_fi, '모델 저장')\n",
    "    \n",
    "    fold_end_time = time.time()\n",
    "    \n",
    "    print(f'{fold_num}fold 훈련 시간: {fold_end_time - fold_start_time} \\n')\n",
    "    \n",
    "    # 메모리 정리\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "total_end_time = time.time()\n",
    "print(f'총 훈련 시간: {total_end_time - total_start_time}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aee6d31-3204-4d9c-b096-dd3973f04ca7",
   "metadata": {},
   "source": [
    "# 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631ce276-82eb-4b71-b87e-d78e7ff584be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# submission 데이터 정의\n",
    "submission_dataset = CustomDataset(df = submission, \n",
    "                                   cfg = config,\n",
    "                                   transform = transform['val'],\n",
    "                                   mode = False,\n",
    "                                  )\n",
    "\n",
    "submission_loder = DataLoader(submission_dataset,\n",
    "                                batch_size = config.batch_size,\n",
    "                                num_workers = config.num_workers,\n",
    "                                shuffle = False,\n",
    "                             )\n",
    "\n",
    "submission_label_oof = np.zeros((submission.shape[0], config.num_classes))\n",
    "\n",
    "pre_df = preprocessing_df(df = df, swap_gender_li = swap_gender_li)\n",
    "train_df = make_train_df(df = pre_df, swap_mask_li = swap_mask_li, cfg = config)\n",
    "\n",
    "all_idx_li = pre_df.index.tolist()\n",
    "val_idx_li = get_val_idx(df = pre_df, target_col = config.cv_taget_col)\n",
    "\n",
    "real_labels = []\n",
    "pred_labels = []\n",
    "idx_li = []\n",
    "\n",
    "for fold_num in range(1, config.oof + 1):\n",
    "    fold_start_time = time.time()\n",
    "    \n",
    "    # val\n",
    "    val_idx = next(val_idx_li)\n",
    "    trn_idx = list(set(all_idx_li) - set(val_idx.tolist()))\n",
    "    \n",
    "    val_id_df = pre_df.iloc[val_idx, :]\n",
    "    trn_id_df = pre_df.iloc[trn_idx, :]\n",
    "    \n",
    "    val_df = train_df.set_index('id').loc[val_id_df['id'].tolist(), :].reset_index()\n",
    "    trn_df = train_df.set_index('id').loc[trn_id_df['id'].tolist(), :].reset_index()\n",
    "    \n",
    "    val_dataset = CustomDataset(df = val_df, \n",
    "                                cfg = config,\n",
    "                                transform = transform['val'],\n",
    "                                mode = True,\n",
    "                               )\n",
    "    \n",
    "    val_loder = DataLoader(val_dataset,\n",
    "                            batch_size = config.batch_size,\n",
    "                           num_workers = config.num_workers,\n",
    "                            shuffle = False,)\n",
    "    \n",
    "    # 모델 로드\n",
    "    model = CreateModel(cfg = config, pretrained = False).to(device)\n",
    "    model.load_state_dict(torch.load(os.path.join(config.model_dir, f'{fold_num}fold_{config.model_name}.pt')))\n",
    "    \n",
    "    # val 평가\n",
    "    val_label_pred_li, val_ensemble_pred_li, real_pred_li = get_val_pred_li(model = model, data_loader = val_loder)\n",
    "    \n",
    "    real_labels += real_pred_li\n",
    "    pred_labels += val_label_pred_li\n",
    "    idx_li += val_df['idx'].tolist()\n",
    "    \n",
    "    # submission 평가\n",
    "    submission_label_pred_li, submission_ensemble_pred_li = get_submission_pred_li(model = model, data_loader = submission_loder)\n",
    "    submission_label_oof += submission_ensemble_pred_li / config.oof\n",
    "    \n",
    "    fold_end_time = time.time()\n",
    "\n",
    "    _acc = get_acc_score(y_true = real_pred_li, y_pred = val_label_pred_li)\n",
    "    _f1_score = get_f1_score(y_true = real_pred_li, y_pred = val_label_pred_li)\n",
    "\n",
    "    print(f'{fold_num}fold 훈련 시간: {fold_end_time - fold_start_time}, acc: {_acc}, f1_score: {_f1_score} \\n')\n",
    "\n",
    "# pred_li = submission_label_oof.argmax(1).tolist()\n",
    "# pred_li = [label_cats2labels[i] for i in pred_li]\n",
    "# submission['ans'] = pred_li\n",
    "\n",
    "submission['ans'] = submission_label_oof.argmax(1).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30dc6c8c-71cf-4efc-9ddb-be399c73b230",
   "metadata": {},
   "source": [
    "# 결과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33653a37-8493-4d97-af37-0f1f546ab109",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_f1 = get_f1_score(y_true = real_labels, y_pred = pred_labels)\n",
    "train_acc = get_acc_score(y_true = real_labels, y_pred = pred_labels)\n",
    "train_confusion_matrix = pd.DataFrame((confusion_matrix(y_true = real_labels, y_pred = pred_labels)))\n",
    "print(f'train confusion_matrix')\n",
    "display(train_confusion_matrix.style.background_gradient(cmap='YlOrRd', axis = 1))\n",
    "print(f'train fi : {train_f1:.4f}, train acc: {train_acc:.4f} \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dbd9608-13c6-4866-bce9-309ce4387da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels 로 masks, genders, ages 역추적\n",
    "labels2masks_genders_ages = {}\n",
    "for line in train_df[~(train_df.duplicated(subset=[config.tagets_col]))].iloc:\n",
    "    labels2masks_genders_ages[line[config.tagets_col]] = str(line['masks']) + '-' + str(line['genders']) + '-' + str(line['ages'])\n",
    "\n",
    "# 틀린 이미지 시각화\n",
    "image_show_df = train_df.iloc[idx_li, :].reset_index(drop =True)\n",
    "image_show_df['pred_labels'] = pred_labels\n",
    "false_image_show_df = image_show_df[image_show_df[config.tagets_col] != image_show_df['pred_labels']]\n",
    "labels_li = [i for i in range(config.num_classes)]\n",
    "for labels in labels_li:\n",
    "    _false_image_show_df = false_image_show_df[false_image_show_df[config.tagets_col] == labels]\n",
    "    path_labels_pred_labels_li = _false_image_show_df[['path', config.tagets_col, 'pred_labels']].values[:7]\n",
    "    \n",
    "    idx = 0\n",
    "    fig, ax = plt.subplots(1, 7, figsize = (30, 15))\n",
    "    ax = ax.flatten()\n",
    "    for path_labels_pred_labels in path_labels_pred_labels_li:\n",
    "        img = Image.open(path_labels_pred_labels[0])\n",
    "        img = np.array(img)\n",
    "        ax[idx].imshow(img)\n",
    "        ax[idx].set_title(f'true {path_labels_pred_labels[1]} - {labels2masks_genders_ages[path_labels_pred_labels[1]]} / pred {path_labels_pred_labels[2]} - {labels2masks_genders_ages[path_labels_pred_labels[2]]} ')\n",
    "        ax[idx].set_xticks([])\n",
    "        ax[idx].set_yticks([])\n",
    "        idx += 1\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a4b84b-969f-4c34-a784-9738b243e534",
   "metadata": {},
   "source": [
    "# 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f96cbb-37d3-49ae-a5f2-9e2de27eeea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(os.path.join(config.submission_data_dir, config.file_name), index=False)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a7c1fa-7caf-4528-b054-bc4eedb2ee29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
